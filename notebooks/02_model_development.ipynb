{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd498257",
   "metadata": {},
   "source": [
    "# Bottle Cap Detection - Model Development\n",
    "**Author:** Wikan Priambudi\n",
    "**Goal:** Develop a lightweight detection model (<10ms inference) for Raspberry Pi 5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a23f84",
   "metadata": {},
   "source": [
    "## Setting wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2be6fa59-ffe6-435f-9924-06eefb741852",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwikan\u001b[0m (\u001b[33mwikan-project\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WandB Integration: Active\n"
     ]
    }
   ],
   "source": [
    "import wandb\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Login ke WandB (Nanti akan muncul input box untuk API Key)\n",
    "wandb.login()\n",
    "\n",
    "# 3. Pastikan integrasi Ultralytics aktif\n",
    "from ultralytics import settings\n",
    "settings.update({'wandb': True})\n",
    "print(\"WandB Integration: Active\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f35c5a",
   "metadata": {},
   "source": [
    "### ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdae657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO, settings\n",
    "import onnxruntime as ort\n",
    "import numpy as np\n",
    "import time\n",
    "import wandb\n",
    "import os\n",
    "\n",
    "# --- KONFIGURASI GLOBAL ---\n",
    "PROJECT_NAME = \"Bottle-Cap-Detection\"\n",
    "DATA_YAML = '../datasets/bottle_cap/data.yaml'\n",
    "\n",
    "# Aktifkan integrasi Ultralytics -> W&B\n",
    "settings.update({'wandb': True})\n",
    "\n",
    "def run_experiment(model_name, exp_name, img_size=320, use_safe_aug=False):\n",
    "    \"\"\"\n",
    "    Fungsi SATU PINTU: Training -> Export ONNX -> Benchmark Speed -> Upload ke WandB.\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸš€ START EXPERIMENT: {exp_name} | Size: {img_size} | Safe Aug: {use_safe_aug}\")\n",
    "\n",
    "    # ===========================\n",
    "    # 1. INISIALISASI WANDB & SIMPAN ID (INI YANG HILANG TADI)\n",
    "    # ===========================\n",
    "    # Bersihkan sesi nyangkut\n",
    "    if wandb.run is not None: wandb.finish()\n",
    "    \n",
    "    # Init run baru\n",
    "    run = wandb.init(project=PROJECT_NAME, name=exp_name, job_type=\"train_and_eval\")\n",
    "    my_run_id = run.id  # <--- KITA SIMPAN KUNCINYA DISINI!\n",
    "    \n",
    "    # Kita biarkan sesi ini AKTIF saat masuk ke model.train\n",
    "    # Ultralytics otomatis akan mendeteksi sesi aktif ini dan \"menumpang\" di situ.\n",
    "    \n",
    "    try:\n",
    "        # ===========================\n",
    "        # TAHAP 2: TRAINING\n",
    "        # ===========================\n",
    "        model = YOLO(model_name)\n",
    "\n",
    "        train_args = {\n",
    "            \"data\": DATA_YAML,\n",
    "            \"epochs\": 50, # Bisa dinaikkan nanti\n",
    "            \"imgsz\": img_size,\n",
    "            \"batch\": 8,\n",
    "            \"patience\": 15,\n",
    "            \"project\": PROJECT_NAME, \n",
    "            \"name\": exp_name,\n",
    "            \"device\": \"cpu\",\n",
    "            \"plots\": True,\n",
    "            \"exist_ok\": True,\n",
    "        }\n",
    "\n",
    "        if use_safe_aug:\n",
    "            print(\"ğŸ›¡ï¸ Mengaktifkan SAFE MODE...\")\n",
    "            train_args.update({\n",
    "                \"mosaic\": 0.0, \"scale\": 0.1, \"degrees\": 0.0,\n",
    "                \"hsv_h\": 0.0, \"hsv_s\": 0.0, \"hsv_v\": 0.0\n",
    "            })\n",
    "\n",
    "        # Training\n",
    "        # Ultralytics akan menggunakan run yang sudah kita init di atas\n",
    "        model.train(**train_args)\n",
    "\n",
    "        print(\"ğŸ“Š Running Validation...\")\n",
    "        metrics = model.val()\n",
    "        \n",
    "        # ===========================\n",
    "        # TAHAP 3: EXPORT ONNX\n",
    "        # ===========================\n",
    "        print(\"ğŸ“¦ Exporting to ONNX...\")\n",
    "        model.export(format='onnx', dynamic=False, opset=12, imgsz=img_size)\n",
    "\n",
    "        onnx_path = os.path.join(PROJECT_NAME, exp_name, 'weights', 'best.onnx')\n",
    "        if not os.path.exists(onnx_path):\n",
    "            onnx_path = f\"{PROJECT_NAME}/{exp_name}/weights/best.onnx\"\n",
    "\n",
    "        if not os.path.exists(onnx_path):\n",
    "            print(\"âŒ File ONNX tidak ditemukan, skip benchmark.\")\n",
    "            return 0\n",
    "\n",
    "        # ===========================\n",
    "        # TAHAP 4: BENCHMARK ONNX\n",
    "        # ===========================\n",
    "        print(f\"â±ï¸ Running Benchmark on: {onnx_path}\")\n",
    "        session = ort.InferenceSession(onnx_path)\n",
    "        input_name = session.get_inputs()[0].name\n",
    "        dummy_input = np.random.randn(1, 3, img_size, img_size).astype(np.float32)\n",
    "\n",
    "        # Warmup\n",
    "        for _ in range(10): session.run(None, {input_name: dummy_input})\n",
    "\n",
    "        # Testing loop\n",
    "        start = time.time()\n",
    "        for _ in range(50): session.run(None, {input_name: dummy_input})\n",
    "        \n",
    "        avg_ms = (time.time() - start) / 50 * 1000\n",
    "        fps = 1000 / avg_ms\n",
    "\n",
    "        print(f\"âœ… Speed Result: {avg_ms:.2f} ms ({fps:.1f} FPS)\")\n",
    "\n",
    "        # ===========================\n",
    "        # TAHAP 5: LOGGING & FINISH\n",
    "        # ===========================\n",
    "        # Cek status run. Jika Ultralytics menutupnya, kita buka lagi pakai ID lama.\n",
    "        if wandb.run is None:\n",
    "            print(f\"ğŸ”„ Re-connecting ke Run ID: {my_run_id}...\")\n",
    "            wandb.init(id=my_run_id, project=PROJECT_NAME, resume=\"must\")\n",
    "\n",
    "        # Log data benchmark\n",
    "        log_data = {\n",
    "            \"inference/latency_ms\": avg_ms,\n",
    "            \"inference/onnx_fps\": fps,\n",
    "            \"model/size_mb\": os.path.getsize(onnx_path) / (1024 * 1024),\n",
    "            \"val/mAP50\": metrics.box.map50 \n",
    "        }\n",
    "        \n",
    "        wandb.log(log_data)\n",
    "        \n",
    "        # Update summary agar muncul di bar chart dashboard\n",
    "        for key, value in log_data.items():\n",
    "            wandb.run.summary[key] = value\n",
    "\n",
    "        print(\"âœ… Data benchmark berhasil dikirim ke WandB!\")\n",
    "        return avg_ms\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error terjadi: {e}\")\n",
    "        raise e\n",
    "        \n",
    "    finally:\n",
    "        # Pastikan sesi selalu ditutup di akhir\n",
    "        if wandb.run is not None:\n",
    "            wandb.finish()\n",
    "            print(\"ğŸ”’ Sesi WandB ditutup.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53401dcd",
   "metadata": {},
   "source": [
    "### FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b769242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO, settings\n",
    "import numpy as np\n",
    "import time\n",
    "import wandb\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "# --- KONFIGURASI GLOBAL ---\n",
    "PROJECT_NAME = \"Bottle-Cap-Detection\"\n",
    "DATA_YAML = '../datasets/bottle_cap/data.yaml'\n",
    "\n",
    "# Pastikan setting Ultralytics connect ke WandB\n",
    "settings.update({'wandb': True})\n",
    "\n",
    "def run_experiment_fp16(model_name, exp_name, img_size=320, use_safe_aug=False):\n",
    "    \"\"\"\n",
    "    Fungsi SATU PINTU: Training -> Export OpenVINO FP16 -> Benchmark -> Upload WandB.\n",
    "    \"\"\"\n",
    "    print(f\"\\nğŸš€ START FP16 EXPERIMENT: {exp_name} | Size: {img_size} | Safe Aug: {use_safe_aug}\")\n",
    "\n",
    "    # 1. INISIALISASI WANDB\n",
    "    if wandb.run is not None: wandb.finish()\n",
    "    \n",
    "    run = wandb.init(project=PROJECT_NAME, name=exp_name, job_type=\"train_and_eval_fp16\")\n",
    "    my_run_id = run.id\n",
    "    \n",
    "    try:\n",
    "        # ===========================\n",
    "        # TAHAP 2: TRAINING\n",
    "        # ===========================\n",
    "        model = YOLO(model_name)\n",
    "        \n",
    "        train_args = {\n",
    "            \"data\": DATA_YAML,\n",
    "            \"epochs\": 50,  \n",
    "            \"imgsz\": img_size,\n",
    "            \"batch\": 8,\n",
    "            \"patience\": 15,\n",
    "            \"project\": PROJECT_NAME, \n",
    "            \"name\": exp_name,\n",
    "            \"device\": \"cpu\", \n",
    "            \"plots\": True,\n",
    "            \"exist_ok\": True,\n",
    "        }\n",
    "\n",
    "        if use_safe_aug:\n",
    "            print(\"ğŸ›¡ï¸ Mengaktifkan SAFE MODE (Augmentasi Warna OFF)...\")\n",
    "            train_args.update({\n",
    "                \"mosaic\": 0.0, \"scale\": 0.1, \"degrees\": 0.0,\n",
    "                \"hsv_h\": 0.0, \"hsv_s\": 0.0, \"hsv_v\": 0.0\n",
    "            })\n",
    "        \n",
    "        # Training\n",
    "        model.train(**train_args)\n",
    "        \n",
    "        print(\"ğŸ“Š Running Validation...\")\n",
    "        metrics = model.val()\n",
    "        \n",
    "        # ===========================\n",
    "        # TAHAP 3: EXPORT OPENVINO FP16\n",
    "        # ===========================\n",
    "        print(\"\\nğŸ“¦ Exporting to OpenVINO FP16...\")\n",
    "        \n",
    "        # Hapus folder lama jika ada (untuk menghindari error permission di Windows)\n",
    "        save_dir = Path(f'{PROJECT_NAME}/{exp_name}/weights')\n",
    "        ov_old_dirs = list(save_dir.glob('*openvino*'))\n",
    "        for d in ov_old_dirs:\n",
    "            try:\n",
    "                shutil.rmtree(d)\n",
    "                print(\"   (Folder export lama dihapus)\")\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # Export command dengan half=True\n",
    "        ov_path_result = model.export(\n",
    "            format='openvino', \n",
    "            imgsz=img_size, \n",
    "            half=True,   # <--- INI KUNCI FP16 (Half Precision)\n",
    "            dynamic=False\n",
    "        )\n",
    "        \n",
    "        # Cari folder hasil export (biasanya best_openvino_model)\n",
    "        ov_dirs = list(save_dir.glob('*openvino*'))\n",
    "        if not ov_dirs:\n",
    "            print(\"âŒ Folder OpenVINO tidak ditemukan, skip benchmark.\")\n",
    "            return 0\n",
    "            \n",
    "        model_ov_path = str(ov_dirs[0]) # Path ke folder model OpenVINO\n",
    "\n",
    "        # ===========================\n",
    "        # TAHAP 4: BENCHMARK OPENVINO FP16\n",
    "        # ===========================\n",
    "        print(f\"â±ï¸ Running Benchmark on: {model_ov_path}\")\n",
    "        \n",
    "        # Load model OpenVINO menggunakan Ultralytics Wrapper\n",
    "        # (Ini cara paling stabil karena otomatis handle preprocessing)\n",
    "        model_ov = YOLO(model_ov_path, task='detect')\n",
    "        \n",
    "        # Kita butuh gambar dummy/real untuk predict() method Ultralytics\n",
    "        # Opsi A: Pakai gambar random (numpy)\n",
    "        dummy_img = np.random.randint(0, 255, (img_size, img_size, 3), dtype=np.uint8)\n",
    "        \n",
    "        # Warmup (10x)\n",
    "        for _ in range(10): \n",
    "            model_ov.predict(source=dummy_img, imgsz=img_size, verbose=False)\n",
    "\n",
    "        # Testing (50x)\n",
    "        start = time.time()\n",
    "        for _ in range(50):\n",
    "            model_ov.predict(source=dummy_img, imgsz=img_size, verbose=False)\n",
    "        \n",
    "        avg_ms = (time.time() - start) / 50 * 1000\n",
    "        fps = 1000 / avg_ms\n",
    "        \n",
    "        print(f\"âœ… Speed Result (FP16): {avg_ms:.2f} ms ({fps:.1f} FPS)\")\n",
    "        \n",
    "        # ===========================\n",
    "        # TAHAP 5: LOGGING & FINISH\n",
    "        # ===========================\n",
    "        if wandb.run is None:\n",
    "            print(f\"ğŸ”„ Re-connecting ke Run ID: {my_run_id}...\")\n",
    "            wandb.init(id=my_run_id, project=PROJECT_NAME, resume=\"must\")\n",
    "            \n",
    "        # Hitung ukuran folder model (karena OpenVINO isinya folder .xml & .bin)\n",
    "        model_size_mb = sum(f.stat().st_size for f in Path(model_ov_path).glob('**/*') if f.is_file()) / (1024 * 1024)\n",
    "\n",
    "        log_data = {\n",
    "            \"inference/latency_ms\": avg_ms,\n",
    "            \"inference/openvino_fp16_fps\": fps, # Ganti nama biar beda dengan ONNX\n",
    "            \"model/size_mb\": model_size_mb,\n",
    "            \"val/mAP50\": metrics.box.map50,\n",
    "            \"precision\": \"FP16\"\n",
    "        }\n",
    "        \n",
    "        wandb.log(log_data)\n",
    "        \n",
    "        # Update summary\n",
    "        for key, value in log_data.items():\n",
    "            wandb.run.summary[key] = value\n",
    "            \n",
    "        print(\"âœ… Data FP16 berhasil dikirim ke WandB!\")\n",
    "        return avg_ms\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Experiment Failed: {e}\")\n",
    "        raise e\n",
    "        \n",
    "    finally:\n",
    "        if wandb.run is not None:\n",
    "            wandb.finish()\n",
    "            print(\"ğŸ”’ WandB Session Closed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e293d",
   "metadata": {},
   "source": [
    "## YOLOv8n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d46f26ac-c805-4c49-85e1-e1313579d8b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ START EXPERIMENT: yolov8n_640 | Size: 640 | Safe Aug: False\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_091049-97bnxdfm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/97bnxdfm' target=\"_blank\">yolov8n_640</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/97bnxdfm' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/97bnxdfm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../datasets/bottle_cap/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n_640, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=Bottle-Cap-Detection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_640, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 2.20.6 ms, read: 2.30.6 MB/s, size: 54.5 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\train\\labels.cache... 9 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 1.60.4 ms, read: 1.90.5 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.7Kit/s 0.0s\n",
      "Plotting labels to G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_640\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_640\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50         0G      1.164      3.919     0.9741          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0s/it 4.0s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.6it/s 0.6s\n",
      "                   all          3         19    0.00119     0.0476     0.0166    0.00831\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50         0G      1.114      3.754      0.939          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.5s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19    0.00208     0.0952     0.0254     0.0124\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50         0G     0.8751      3.714     0.8563         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.1s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19    0.00296      0.143     0.0259     0.0155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50         0G     0.7149      3.512     0.8502         14        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.4s\n",
      "                   all          3         19    0.00415       0.19     0.0427     0.0172\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50         0G     0.9008      3.364      0.841          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 2.9s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.5s\n",
      "                   all          3         19    0.00612      0.286      0.061      0.023\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50         0G     0.9466      2.879      0.917          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 2.9s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "                   all          3         19     0.0132      0.629      0.126       0.06\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50         0G     0.8305      2.638     0.8452         10        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.1s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.4s\n",
      "                   all          3         19     0.0188      0.886      0.329      0.179\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50         0G     0.8183      2.701     0.9181          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19     0.0211          1      0.422      0.222\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50         0G     0.8374      2.004     0.8795          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19     0.0211          1      0.425      0.256\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50         0G     0.7228      2.025     0.8198         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.1s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19      0.021          1      0.491      0.343\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50         0G     0.6348      1.424     0.8131          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 2.9s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19      0.021          1      0.441      0.281\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50         0G     0.6592      1.658     0.8203         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19      0.021          1      0.441      0.281\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50         0G     0.7056      2.013     0.7916          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19      0.021          1      0.458      0.254\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50         0G     0.6129      1.464     0.8191          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "                   all          3         19      0.021          1      0.479      0.252\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50         0G     0.7042      3.286     0.8854          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "                   all          3         19      0.021          1      0.479      0.252\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50         0G     0.6335      1.764     0.8503          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.1s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19     0.0211          1      0.511      0.282\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50         0G     0.5911      1.304     0.8069         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19     0.0212          1      0.517      0.298\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50         0G     0.8756      2.153      1.019          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 2.9s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19     0.0212          1      0.517      0.298\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50         0G     0.6682      1.507     0.8353         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.1s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.4s\n",
      "                   all          3         19     0.0212          1      0.606      0.376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50         0G     0.9025      1.972     0.8217         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19     0.0212          1      0.606      0.376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50         0G     0.6217      1.799     0.8637          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 2.9s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "                   all          3         19     0.0215          1      0.618      0.436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50         0G     0.5853      1.554     0.8008          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "                   all          3         19     0.0215          1      0.618      0.436\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50         0G     0.5913      1.425     0.8378         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.1s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19      0.022          1      0.667      0.493\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50         0G     0.5946       1.51     0.8367         23        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.9s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
      "                   all          3         19      0.022          1      0.667      0.493\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50         0G     0.5334      1.578     0.8235          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.1s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19     0.0221          1      0.683      0.495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50         0G     0.5735      1.412     0.8487          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.7s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "                   all          3         19     0.0221          1      0.683      0.495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50         0G      0.569      1.378     0.8171          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.9s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19     0.0221          1      0.683      0.495\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50         0G     0.4853      1.293     0.8189          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.1s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19     0.0222          1      0.697      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50         0G     0.5485      1.378       0.85          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.5s\n",
      "                   all          3         19     0.0222          1      0.697      0.546\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50         0G     0.5718      1.495     0.8432          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9s/it 3.7s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19     0.0221          1      0.791      0.657\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50         0G     0.6599      1.361     0.9194          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.3s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19     0.0221          1      0.791      0.657\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50         0G     0.6583      1.107     0.8627          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.5s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19     0.0221          1      0.791      0.657\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50         0G     0.6112      1.087     0.8063         20        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.4s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.734      0.857      0.853      0.721\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50         0G     0.5328     0.8981     0.8473          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.1s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19      0.734      0.857      0.853      0.721\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50         0G     0.6187     0.9921     0.8351         21        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.4s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.5s\n",
      "                   all          3         19      0.734      0.857      0.853      0.721\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50         0G     0.5644     0.9218     0.8116         12        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.8s/it 3.7s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19          1     0.0931      0.919      0.814\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50         0G     0.4676     0.7813      0.844         11        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19          1     0.0931      0.919      0.814\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50         0G     0.4843      1.122     0.8007          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19          1     0.0931      0.919      0.814\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50         0G        0.6      1.055     0.8238          9        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.0s/it 6.0s3.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.3it/s 0.7s\n",
      "                   all          3         19          1      0.531      0.964      0.851\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50         0G     0.5404        1.3     0.8456         32        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1s/it 4.1s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.5it/s 0.6s\n",
      "                   all          3         19          1      0.531      0.964      0.851\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50         0G     0.5264      1.038     0.8643          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0s/it 4.0s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
      "                   all          3         19          1      0.531      0.964      0.851\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50         0G     0.6329      1.151     0.8683          3        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.2s/it 4.5s3.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.6it/s 0.6s\n",
      "                   all          3         19      0.964      0.675      0.974      0.878\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50         0G     0.5057        1.1     0.8992          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9s/it 3.9s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
      "                   all          3         19      0.964      0.675      0.974      0.878\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50         0G     0.5276      1.247     0.8212          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0s/it 3.9s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.6s\n",
      "                   all          3         19      0.964      0.675      0.974      0.878\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50         0G     0.5645     0.9286     0.8214          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.2s/it 4.4s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.4it/s 0.7s\n",
      "                   all          3         19      0.964      0.675      0.974      0.878\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50         0G     0.6585     0.9617     0.8089          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.2s/it 4.4s2.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.6s\n",
      "                   all          3         19      0.956       0.85      0.985      0.892\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50         0G     0.5672     0.9481      0.821          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9s/it 3.8s2.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.6it/s 0.6s\n",
      "                   all          3         19      0.956       0.85      0.985      0.892\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50         0G     0.4257       1.24     0.7452          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9s/it 3.8s2.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.5s\n",
      "                   all          3         19      0.956       0.85      0.985      0.892\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50         0G     0.4345      1.374     0.7781          5        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0s/it 4.0s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.5it/s 0.7s\n",
      "                   all          3         19      0.956       0.85      0.985      0.892\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50         0G     0.5055       1.04     0.8417          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.4s/it 4.8s2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.6it/s 0.6s\n",
      "                   all          3         19      0.949      0.885      0.981      0.884\n",
      "\n",
      "50 epochs completed in 0.062 hours.\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_640\\weights\\last.pt, 6.1MB\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_640\\weights\\best.pt, 6.1MB\n",
      "\n",
      "Validating G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_640\\weights\\best.pt...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
      "                   all          3         19      0.956       0.85      0.985      0.892\n",
      "            light_blue          1          5      0.868          1      0.995      0.935\n",
      "             dark_blue          1          7          1      0.862      0.995      0.836\n",
      "                others          1          7          1      0.689      0.964      0.903\n",
      "Speed: 0.9ms preprocess, 104.8ms inference, 0.0ms loss, 8.6ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_640\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Tried to log to step 50 that is less than the current step 51. Steps must be monotonically increasing, so this data will be ignored. See https://wandb.me/define-metric to log data out of order.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg1</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–„â–ƒâ–‚</td></tr><tr><td>lr/pg2</td><td>â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>metrics/mAP50(B)</td><td>â–â–â–â–â–â–ƒâ–„â–„â–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/mAP50-95(B)</td><td>â–â–â–â–â–â–‚â–ƒâ–ƒâ–„â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/precision(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–†â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/recall(B)</td><td>â–â–‚â–‚â–ƒâ–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–â–â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡</td></tr><tr><td>model/GFLOPs</td><td>â–</td></tr><tr><td>model/parameters</td><td>â–</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>â–</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.981</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.88368</td></tr><tr><td>metrics/precision(B)</td><td>0.94865</td></tr><tr><td>metrics/recall(B)</td><td>0.88457</td></tr><tr><td>model/GFLOPs</td><td>8.196</td></tr><tr><td>model/parameters</td><td>3011433</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>110.418</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolov8n_640</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/97bnxdfm' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/97bnxdfm</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 20 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_091049-97bnxdfm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Running Validation...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 1.90.6 ms, read: 2.30.5 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.9Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.5s\n",
      "                   all          3         19      0.956       0.85      0.985      0.892\n",
      "            light_blue          1          5      0.868          1      0.995      0.935\n",
      "             dark_blue          1          7          1      0.862      0.995      0.836\n",
      "                others          1          7          1      0.689      0.964      0.903\n",
      "Speed: 0.9ms preprocess, 96.8ms inference, 0.0ms loss, 8.3ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\runs\\detect\\val42\u001b[0m\n",
      "ğŸ“¦ Exporting to ONNX...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_640\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 7, 8400) (6.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.74...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.5s, saved as 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_640\\weights\\best.onnx' (11.7 MB)\n",
      "\n",
      "Export complete (2.9s)\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_640\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_640\\weights\\best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_640\\weights\\best.onnx imgsz=640 data=../datasets/bottle_cap/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "â±ï¸ Running Benchmark on: Bottle-Cap-Detection\\yolov8n_640\\weights\\best.onnx\n",
      "âœ… Speed Result: 124.79 ms (8.0 FPS)\n",
      "ğŸ”„ Re-connecting ke Run ID: 97bnxdfm...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_091533-97bnxdfm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/97bnxdfm' target=\"_blank\">yolov8n_640</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/97bnxdfm' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/97bnxdfm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data benchmark berhasil dikirim ke WandB!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>â–</td></tr><tr><td>inference/onnx_fps</td><td>â–</td></tr><tr><td>model/size_mb</td><td>â–</td></tr><tr><td>val/mAP50</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>124.7909</td></tr><tr><td>inference/onnx_fps</td><td>8.0134</td></tr><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.981</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.88368</td></tr><tr><td>metrics/precision(B)</td><td>0.94865</td></tr><tr><td>metrics/recall(B)</td><td>0.88457</td></tr><tr><td>model/GFLOPs</td><td>8.196</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolov8n_640</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/97bnxdfm' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/97bnxdfm</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_091533-97bnxdfm\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”’ Sesi WandB ditutup.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "124.79090213775635"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jalankan Eksperimen 1: Ukuran 320, Augmentasi Aman\n",
    "run_experiment(\n",
    "    model_name='yolov8n.pt', \n",
    "    exp_name='yolov8n_640', \n",
    "    img_size=640, \n",
    "    use_safe_aug=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a91c821",
   "metadata": {},
   "source": [
    "### Change size into 320"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c24c56fe-2cfe-4ee6-8517-3c7fa23cd821",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ START EXPERIMENT: yolov8n_320 | Size: 320 | Safe Aug: False\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_091537-p9b5yfnu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/p9b5yfnu' target=\"_blank\">yolov8n_320</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/p9b5yfnu' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/p9b5yfnu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../datasets/bottle_cap/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov8n_320, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=Bottle-Cap-Detection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 1.60.4 ms, read: 2.70.6 MB/s, size: 52.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\train\\labels.cache... 9 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 9.1Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 2.00.0 ms, read: 2.30.6 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.5Kit/s 0.0s\n",
      "Plotting labels to G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50         0G      1.768      4.127     0.9598          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2s/it 2.4s2.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19     0.0159      0.667     0.0268     0.0187\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50         0G      1.814      4.124     0.9852          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.1s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.5it/s 0.3s\n",
      "                   all          3         19     0.0173      0.714     0.0312     0.0217\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50         0G      1.676      4.111     0.8831         18        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.1s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
      "                   all          3         19      0.023      0.857     0.0364     0.0215\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50         0G     0.9304      3.853     0.8661          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19     0.0269          1     0.0483     0.0189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50         0G      1.037      3.811      0.835          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19     0.0259          1     0.0484     0.0188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50         0G      1.086      3.703     0.8399         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19     0.0247          1     0.0492     0.0227\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50         0G      1.341       3.63     0.8281         24        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 1.9s2.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19      0.024          1     0.0499     0.0295\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50         0G      1.246      3.225     0.8428          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s2.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8it/s 0.3s\n",
      "                   all          3         19     0.0227          1     0.0446     0.0326\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50         0G      1.185      3.361     0.8222         24        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19     0.0222          1     0.0444     0.0337\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50         0G      1.006      3.002     0.8351         17        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 1.9s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6it/s 0.3s\n",
      "                   all          3         19     0.0219          1     0.0456     0.0331\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50         0G     0.8294      2.404     0.8359          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.2it/s 0.2s\n",
      "                   all          3         19     0.0216          1     0.0482     0.0303\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50         0G      1.111       1.81     0.7896          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19     0.0216          1     0.0482     0.0303\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50         0G      1.086      2.092     0.8088          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.0it/s 0.3s\n",
      "                   all          3         19     0.0214          1      0.228      0.145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50         0G     0.8733      2.143     0.8137         16        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.9it/s 0.3s\n",
      "                   all          3         19     0.0212          1       0.31      0.214\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50         0G      0.896      2.132     0.7988         14        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.6s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8it/s 0.3s\n",
      "                   all          3         19     0.0212          1       0.31      0.214\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50         0G       1.11      2.547     0.7988         21        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19     0.0211          1      0.372      0.276\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50         0G      1.103      1.864     0.8353         21        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19      0.021          1      0.437      0.322\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50         0G     0.7526      1.581     0.7551         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.6s1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19      0.021          1      0.437      0.322\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50         0G     0.9324      1.543     0.7913         22        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.6s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
      "                   all          3         19      0.021          1      0.505      0.358\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50         0G     0.7035      1.047     0.7904          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.1it/s 0.3s\n",
      "                   all          3         19      0.021          1      0.505      0.358\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50         0G     0.7978      2.887     0.8343          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19          1     0.0927      0.597      0.434\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50         0G     0.8737      1.951     0.7893          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.6s1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19          1     0.0927      0.597      0.434\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50         0G     0.9196       1.55     0.7985          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1s/it 2.1s3.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19          1     0.0845      0.607      0.457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50         0G     0.6455      1.072       0.83          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.5s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
      "                   all          3         19          1     0.0845      0.607      0.457\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50         0G      1.003      2.334     0.8308          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19          1     0.0894      0.613       0.48\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50         0G      1.089      2.112     0.7834         11        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19          1     0.0894      0.613       0.48\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50         0G      1.098      1.494     0.8233          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.5s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.9it/s 0.3s\n",
      "                   all          3         19          1     0.0894      0.613       0.48\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50         0G      1.071      1.586      0.799         19        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.7it/s 0.3s\n",
      "                   all          3         19          1     0.0932      0.624      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50         0G     0.8495       1.37     0.8093         22        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.5s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8it/s 0.3s\n",
      "                   all          3         19          1     0.0932      0.624      0.509\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50         0G     0.9708      1.696     0.8104         21        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s2.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19          1      0.134      0.634      0.539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50         0G     0.8214      1.473     0.8434         15        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19          1      0.134      0.634      0.539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50         0G     0.8051      1.371     0.7938         15        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.9it/s 0.3s\n",
      "                   all          3         19          1      0.134      0.634      0.539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50         0G     0.8521      1.572     0.7962          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 1.9s1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19          1      0.159      0.655      0.544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50         0G     0.7504      1.291     0.8321          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19          1      0.159      0.655      0.544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50         0G      0.815      1.659     0.8149          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.6s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.9it/s 0.3s\n",
      "                   all          3         19          1      0.159      0.655      0.544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50         0G     0.7001      1.249     0.7864         15        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6it/s 0.3s\n",
      "                   all          3         19      0.926       0.28      0.671      0.528\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50         0G     0.6215      1.078      0.821          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.5it/s 0.3s\n",
      "                   all          3         19      0.926       0.28      0.671      0.528\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50         0G     0.7446      1.085      0.764          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19      0.926       0.28      0.671      0.528\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50         0G      1.205      1.361     0.8147         16        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.9it/s 0.3s\n",
      "                   all          3         19      0.621      0.599        0.7      0.544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50         0G     0.8141      1.479     0.8212         25        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8it/s 0.3s\n",
      "                   all          3         19      0.621      0.599        0.7      0.544\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50         0G      0.774      1.647     0.8544          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19      0.621      0.599        0.7      0.544\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50         0G     0.6668      1.259     0.6937          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6it/s 0.3s\n",
      "                   all          3         19      0.654      0.889      0.741      0.584\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50         0G     0.6195      1.066     0.8142          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.5s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6it/s 0.3s\n",
      "                   all          3         19      0.654      0.889      0.741      0.584\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50         0G     0.8669      2.122     0.7963          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8it/s 0.3s\n",
      "                   all          3         19      0.654      0.889      0.741      0.584\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50         0G     0.7132     0.9646     0.7878          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
      "                   all          3         19      0.654      0.889      0.741      0.584\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50         0G      0.586     0.9689     0.8244          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.7s1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19      0.657      0.868       0.75      0.611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50         0G     0.5508     0.8929     0.7853          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.5s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.9it/s 0.3s\n",
      "                   all          3         19      0.657      0.868       0.75      0.611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50         0G     0.5879      1.651     0.7742          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19      0.657      0.868       0.75      0.611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50         0G     0.6649      1.413     0.7986          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19      0.657      0.868       0.75      0.611\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50         0G     0.6644     0.9927     0.7896          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19      0.635       0.89      0.753      0.611\n",
      "\n",
      "50 epochs completed in 0.036 hours.\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320\\weights\\best.pt...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19      0.658      0.869      0.747      0.609\n",
      "            light_blue          1          5      0.396          1      0.555      0.455\n",
      "             dark_blue          1          7      0.576      0.973      0.709       0.53\n",
      "                others          1          7          1      0.633      0.978      0.842\n",
      "Speed: 0.9ms preprocess, 50.5ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg1</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg2</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>metrics/mAP50(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–ƒâ–„â–„â–„â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/mAP50-95(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–„â–…â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/precision(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–…â–…â–†â–†â–†â–†â–†â–†â–…</td></tr><tr><td>metrics/recall(B)</td><td>â–…â–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–…â–…â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡</td></tr><tr><td>model/GFLOPs</td><td>â–</td></tr><tr><td>model/parameters</td><td>â–</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>â–</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.75276</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.61058</td></tr><tr><td>metrics/precision(B)</td><td>0.63512</td></tr><tr><td>metrics/recall(B)</td><td>0.88952</td></tr><tr><td>model/GFLOPs</td><td>8.196</td></tr><tr><td>model/parameters</td><td>3011433</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>62.317</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolov8n_320</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/p9b5yfnu' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/p9b5yfnu</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 20 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_091537-p9b5yfnu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Running Validation...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 1.90.8 ms, read: 2.00.5 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 8.0it/s 0.1s\n",
      "                   all          3         19      0.658      0.869      0.747      0.609\n",
      "            light_blue          1          5      0.396          1      0.555      0.455\n",
      "             dark_blue          1          7      0.576      0.973      0.709       0.53\n",
      "                others          1          7          1      0.633      0.978      0.842\n",
      "Speed: 0.2ms preprocess, 25.5ms inference, 0.0ms loss, 0.6ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\runs\\detect\\val43\u001b[0m\n",
      "ğŸ“¦ Exporting to ONNX...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320\\weights\\best.pt' with input shape (1, 3, 320, 320) BCHW and output shape(s) (1, 7, 2100) (5.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.74...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.6s, saved as 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320\\weights\\best.onnx' (11.6 MB)\n",
      "\n",
      "Export complete (1.8s)\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320\\weights\\best.onnx imgsz=320  \n",
      "Validate:        yolo val task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320\\weights\\best.onnx imgsz=320 data=../datasets/bottle_cap/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "â±ï¸ Running Benchmark on: Bottle-Cap-Detection\\yolov8n_320\\weights\\best.onnx\n",
      "âœ… Speed Result: 24.81 ms (40.3 FPS)\n",
      "ğŸ”„ Re-connecting ke Run ID: p9b5yfnu...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_091822-p9b5yfnu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/p9b5yfnu' target=\"_blank\">yolov8n_320</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/p9b5yfnu' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/p9b5yfnu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data benchmark berhasil dikirim ke WandB!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>â–</td></tr><tr><td>inference/onnx_fps</td><td>â–</td></tr><tr><td>model/size_mb</td><td>â–</td></tr><tr><td>val/mAP50</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>24.8114</td></tr><tr><td>inference/onnx_fps</td><td>40.30405</td></tr><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.75276</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.61058</td></tr><tr><td>metrics/precision(B)</td><td>0.63512</td></tr><tr><td>metrics/recall(B)</td><td>0.88952</td></tr><tr><td>model/GFLOPs</td><td>8.196</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolov8n_320</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/p9b5yfnu' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/p9b5yfnu</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_091822-p9b5yfnu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”’ Sesi WandB ditutup.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "24.8114013671875"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jalankan Eksperimen 1: Ukuran 320, Augmentasi Aman\n",
    "run_experiment(\n",
    "    model_name='yolov8n.pt', \n",
    "    exp_name='yolov8n_320', \n",
    "    img_size=320, \n",
    "    use_safe_aug=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff697a6b",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "752a20b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ START EXPERIMENT: yolov8n_320_aug | Size: 320 | Safe Aug: True\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_091825-ctp5p9pq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ctp5p9pq' target=\"_blank\">yolov8n_320_aug</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ctp5p9pq' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ctp5p9pq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›¡ï¸ Mengaktifkan SAFE MODE...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../datasets/bottle_cap/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=yolov8n_320_aug, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=Bottle-Cap-Detection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_aug, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.1, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 2.30.2 ms, read: 2.00.2 MB/s, size: 52.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\train\\labels.cache... 9 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 2.10.3 ms, read: 1.80.3 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3  0.0s\n",
      "Plotting labels to G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_aug\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_aug\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50         0G        1.7       4.16     0.8901          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.2s1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.1it/s 0.2s\n",
      "                   all          3         19     0.0162      0.667     0.0263     0.0182\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50         0G      1.667      4.072     0.9346          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.8it/s 0.2s\n",
      "                   all          3         19     0.0217       0.81     0.0349      0.024\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50         0G      1.099      4.049     0.8615          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.2s1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.4it/s 0.2s\n",
      "                   all          3         19     0.0262      0.952      0.044     0.0225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50         0G     0.9541       3.92     0.8524          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9it/s 1.0s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.4it/s 0.2s\n",
      "                   all          3         19     0.0253          1     0.0458     0.0187\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50         0G      1.189      3.607     0.8351          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9it/s 1.0s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.7it/s 0.2s\n",
      "                   all          3         19      0.024          1     0.0419     0.0189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50         0G      1.179      3.507     0.8369          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9it/s 1.0s1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.3it/s 0.2s\n",
      "                   all          3         19     0.0227          1     0.0388     0.0204\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50         0G      1.096      3.218     0.7931          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.6it/s 0.2s\n",
      "                   all          3         19     0.0222          1     0.0371     0.0232\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50         0G      1.036       3.01     0.8312          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9it/s 1.0s1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.7it/s 0.2s\n",
      "                   all          3         19     0.0221          1     0.0366     0.0285\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50         0G     0.8222      2.865     0.8127          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.9it/s 0.2s\n",
      "                   all          3         19     0.0216          1     0.0368     0.0286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50         0G     0.8618      2.444     0.8046         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.2s1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8it/s 0.3s\n",
      "                   all          3         19     0.0218          1     0.0399     0.0304\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50         0G     0.8796      2.357     0.7827          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 0.9s1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.9it/s 0.2s\n",
      "                   all          3         19     0.0216          1      0.102     0.0799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50         0G     0.7645      1.738     0.7741          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 0.9s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.3it/s 0.2s\n",
      "                   all          3         19     0.0216          1      0.102     0.0799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50         0G     0.6648      2.311      0.757          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 1.0s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.7it/s 0.2s\n",
      "                   all          3         19     0.0216          1      0.292      0.187\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50         0G     0.7348      1.429     0.7979          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.2it/s 0.9s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.9it/s 0.2s\n",
      "                   all          3         19     0.0216          1      0.338      0.201\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50         0G     0.7956       1.36     0.7933          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.8it/s 0.2s\n",
      "                   all          3         19     0.0216          1      0.338      0.201\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50         0G     0.7785      1.489     0.7852          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.2s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.4it/s 0.2s\n",
      "                   all          3         19     0.0216          1      0.378      0.223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50         0G     0.6945      1.107     0.7811          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.2s1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.0it/s 0.2s\n",
      "                   all          3         19     0.0215          1      0.485      0.317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50         0G     0.7235      2.141     0.8108          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.2it/s 0.9s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.3it/s 0.2s\n",
      "                   all          3         19     0.0215          1      0.485      0.317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50         0G     0.6537      1.163     0.7913         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 1.0s1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.6it/s 0.2s\n",
      "                   all          3         19     0.0214          1      0.519      0.352\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50         0G      0.772      1.927     0.7868          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.2it/s 0.9s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.4it/s 0.2s\n",
      "                   all          3         19     0.0214          1      0.519      0.352\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50         0G     0.9443      1.387     0.7761          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.6it/s 0.2s\n",
      "                   all          3         19      0.272      0.444      0.578      0.412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50         0G     0.8715      2.139     0.7987          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.3it/s 0.9s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.5it/s 0.2s\n",
      "                   all          3         19      0.272      0.444      0.578      0.412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50         0G     0.7481      2.071     0.7763          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.9it/s 0.2s\n",
      "                   all          3         19      0.939       0.19      0.582      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50         0G     0.7184      1.765     0.7631          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.4it/s 0.8s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.6it/s 0.2s\n",
      "                   all          3         19      0.939       0.19      0.582      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50         0G     0.6543     0.9499      0.804          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.5it/s 0.2s\n",
      "                   all          3         19      0.838      0.242      0.682      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50         0G     0.7515     0.9619     0.7692          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 1.0s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.8it/s 0.2s\n",
      "                   all          3         19      0.838      0.242      0.682      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50         0G     0.6414     0.9856     0.7831          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.2it/s 0.9s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.1it/s 0.2s\n",
      "                   all          3         19      0.838      0.242      0.682      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50         0G     0.8789      1.602     0.8129          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 1.0s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.6it/s 0.2s\n",
      "                   all          3         19      0.685      0.517      0.773      0.606\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50         0G     0.8333       2.24     0.8232          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 1.0s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.9it/s 0.2s\n",
      "                   all          3         19      0.685      0.517      0.773      0.606\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50         0G     0.7581      2.117     0.8222          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.7it/s 0.2s\n",
      "                   all          3         19      0.604      0.676      0.792      0.645\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50         0G     0.5951     0.9244     0.7483          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.2it/s 0.9s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.0it/s 0.2s\n",
      "                   all          3         19      0.604      0.676      0.792      0.645\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50         0G     0.8809      1.298     0.8388          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.2it/s 0.9s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.5it/s 0.2s\n",
      "                   all          3         19      0.604      0.676      0.792      0.645\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50         0G      0.581      1.058     0.7932         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9it/s 1.1s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.6it/s 0.2s\n",
      "                   all          3         19      0.565      0.789      0.782      0.658\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50         0G     0.6859      1.739     0.7723          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.3it/s 0.9s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.3it/s 0.2s\n",
      "                   all          3         19      0.565      0.789      0.782      0.658\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50         0G     0.5396     0.9101     0.8038          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 0.9s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.7it/s 0.2s\n",
      "                   all          3         19      0.565      0.789      0.782      0.658\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50         0G     0.6762      1.317      0.775          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.2it/s 0.2s\n",
      "                   all          3         19      0.578      0.743      0.814      0.703\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50         0G     0.6342     0.9024     0.8143          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.5it/s 0.2s\n",
      "                   all          3         19      0.578      0.743      0.814      0.703\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50         0G     0.6582      1.218     0.7903          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 0.9s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.0it/s 0.2s\n",
      "                   all          3         19      0.578      0.743      0.814      0.703\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50         0G     0.5604     0.8985     0.7916          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.2s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.4it/s 0.2s\n",
      "                   all          3         19      0.764      0.807      0.869      0.738\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50         0G     0.5375      1.031     0.8199         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 0.9s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.5it/s 0.2s\n",
      "                   all          3         19      0.764      0.807      0.869      0.738\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50         0G     0.7221      1.091      0.791          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 1.0s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.4it/s 0.2s\n",
      "                   all          3         19      0.764      0.807      0.869      0.738\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50         0G     0.7102      1.077     0.7843          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.6it/s 0.2s\n",
      "                   all          3         19      0.743      0.826        0.9      0.765\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50         0G     0.5757      0.917     0.7798          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.2it/s 0.9s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.3it/s 0.2s\n",
      "                   all          3         19      0.743      0.826        0.9      0.765\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50         0G     0.7668       1.73      0.765          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.8it/s 1.1s1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.7it/s 0.2s\n",
      "                   all          3         19      0.743      0.826        0.9      0.765\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50         0G     0.6019     0.8591     0.7904          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.2it/s 0.9s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.9it/s 0.2s\n",
      "                   all          3         19      0.743      0.826        0.9      0.765\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50         0G     0.5513     0.8604     0.8078          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9it/s 1.1s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.5it/s 0.2s\n",
      "                   all          3         19      0.762      0.881       0.91      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50         0G     0.5807     0.8166      0.781          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.1s1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.6it/s 0.2s\n",
      "                   all          3         19      0.762      0.881       0.91      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50         0G     0.7539      1.665      0.779          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.0it/s 0.2s\n",
      "                   all          3         19      0.762      0.881       0.91      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50         0G      0.668      1.186     0.7754          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.3it/s 0.9s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.8it/s 0.2s\n",
      "                   all          3         19      0.762      0.881       0.91      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50         0G     0.6056     0.8288     0.7776          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 1.0s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.6it/s 0.2s\n",
      "                   all          3         19      0.811      0.921      0.927      0.802\n",
      "\n",
      "50 epochs completed in 0.023 hours.\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_aug\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_aug\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_aug\\weights\\best.pt...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.6it/s 0.2s\n",
      "                   all          3         19      0.812      0.924      0.927      0.802\n",
      "            light_blue          1          5      0.702          1      0.962      0.799\n",
      "             dark_blue          1          7      0.734      0.792      0.825      0.706\n",
      "                others          1          7          1       0.98      0.995      0.902\n",
      "Speed: 0.3ms preprocess, 27.8ms inference, 0.0ms loss, 1.2ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_aug\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg1</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg2</td><td>â–â–‚â–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>metrics/mAP50(B)</td><td>â–â–â–â–â–â–â–â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–…â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/mAP50-95(B)</td><td>â–â–â–â–â–â–â–â–â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/precision(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–ˆâ–‡â–‡â–‡â–†â–†â–…â–…â–…â–…â–…â–…â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡</td></tr><tr><td>metrics/recall(B)</td><td>â–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ƒâ–â–â–â–â–„â–„â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡</td></tr><tr><td>model/GFLOPs</td><td>â–</td></tr><tr><td>model/parameters</td><td>â–</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>â–</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.92722</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.80243</td></tr><tr><td>metrics/precision(B)</td><td>0.81062</td></tr><tr><td>metrics/recall(B)</td><td>0.92065</td></tr><tr><td>model/GFLOPs</td><td>8.196</td></tr><tr><td>model/parameters</td><td>3011433</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>42.59</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolov8n_320_aug</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ctp5p9pq' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ctp5p9pq</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 20 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_091825-ctp5p9pq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Running Validation...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 1.60.7 ms, read: 1.80.7 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.0Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.4it/s 0.2s\n",
      "                   all          3         19      0.812      0.924      0.927      0.802\n",
      "            light_blue          1          5      0.702          1      0.962      0.799\n",
      "             dark_blue          1          7      0.734      0.792      0.825      0.706\n",
      "                others          1          7          1       0.98      0.995      0.902\n",
      "Speed: 0.2ms preprocess, 23.5ms inference, 0.0ms loss, 1.0ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\runs\\detect\\val44\u001b[0m\n",
      "ğŸ“¦ Exporting to ONNX...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_aug\\weights\\best.pt' with input shape (1, 3, 320, 320) BCHW and output shape(s) (1, 7, 2100) (5.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.74...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  0.9s, saved as 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_aug\\weights\\best.onnx' (11.6 MB)\n",
      "\n",
      "Export complete (1.0s)\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_aug\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_aug\\weights\\best.onnx imgsz=320  \n",
      "Validate:        yolo val task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_aug\\weights\\best.onnx imgsz=320 data=../datasets/bottle_cap/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "â±ï¸ Running Benchmark on: Bottle-Cap-Detection\\yolov8n_320_aug\\weights\\best.onnx\n",
      "âœ… Speed Result: 11.96 ms (83.6 FPS)\n",
      "ğŸ”„ Re-connecting ke Run ID: ctp5p9pq...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_092037-ctp5p9pq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ctp5p9pq' target=\"_blank\">yolov8n_320_aug</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ctp5p9pq' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ctp5p9pq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data benchmark berhasil dikirim ke WandB!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>â–</td></tr><tr><td>inference/onnx_fps</td><td>â–</td></tr><tr><td>model/size_mb</td><td>â–</td></tr><tr><td>val/mAP50</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>11.96108</td></tr><tr><td>inference/onnx_fps</td><td>83.6045</td></tr><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.92722</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.80243</td></tr><tr><td>metrics/precision(B)</td><td>0.81062</td></tr><tr><td>metrics/recall(B)</td><td>0.92065</td></tr><tr><td>model/GFLOPs</td><td>8.196</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolov8n_320_aug</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ctp5p9pq' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ctp5p9pq</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_092037-ctp5p9pq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”’ Sesi WandB ditutup.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.961078643798828"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jalankan Eksperimen 1: Ukuran 320, Augmentasi Aman\n",
    "run_experiment(\n",
    "    model_name='yolov8n.pt', \n",
    "    exp_name='yolov8n_320_aug', \n",
    "    img_size=320, \n",
    "    use_safe_aug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4274f6",
   "metadata": {},
   "source": [
    "### FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d9e4312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ START FP16 EXPERIMENT: yolov8n_320_fp16 | Size: 320 | Safe Aug: True\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_092041-dgi1ex2v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/dgi1ex2v' target=\"_blank\">yolov8n_320_fp16</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/dgi1ex2v' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/dgi1ex2v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›¡ï¸ Mengaktifkan SAFE MODE (Augmentasi Warna OFF)...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../datasets/bottle_cap/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=yolov8n_320_fp16, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=Bottle-Cap-Detection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_fp16, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.1, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 1.70.5 ms, read: 2.00.5 MB/s, size: 52.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\train\\labels.cache... 9 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 8.2Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 2.00.7 ms, read: 1.80.5 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3  0.0s\n",
      "Plotting labels to G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_fp16\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_fp16\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50         0G        1.7       4.16     0.8901          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9it/s 1.0s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.9it/s 0.2s\n",
      "                   all          3         19     0.0162      0.667     0.0263     0.0182\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50         0G      1.667      4.072     0.9346          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.1it/s 0.2s\n",
      "                   all          3         19     0.0217       0.81     0.0349      0.024\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50         0G      1.099      4.049     0.8615          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.7it/s 0.3s\n",
      "                   all          3         19     0.0262      0.952      0.044     0.0225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50         0G     0.9541       3.92     0.8524          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.8it/s 0.2s\n",
      "                   all          3         19     0.0253          1     0.0458     0.0187\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50         0G      1.189      3.607     0.8351          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.8it/s 1.1s1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.1it/s 0.2s\n",
      "                   all          3         19      0.024          1     0.0419     0.0189\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50         0G      1.179      3.507     0.8369          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.2s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19     0.0227          1     0.0388     0.0204\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50         0G      1.096      3.218     0.7931          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.8it/s 1.1s1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.8it/s 0.2s\n",
      "                   all          3         19     0.0222          1     0.0371     0.0232\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50         0G      1.036       3.01     0.8312          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.2s1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.0it/s 0.2s\n",
      "                   all          3         19     0.0221          1     0.0366     0.0285\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50         0G     0.8222      2.865     0.8127          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.5s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19     0.0216          1     0.0368     0.0286\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50         0G     0.8618      2.444     0.8046         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.2s1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.3it/s 0.2s\n",
      "                   all          3         19     0.0218          1     0.0399     0.0304\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50         0G     0.8796      2.357     0.7827          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9it/s 1.0s1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.1it/s 0.2s\n",
      "                   all          3         19     0.0216          1      0.102     0.0799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50         0G     0.7645      1.738     0.7741          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19     0.0216          1      0.102     0.0799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50         0G     0.6648      2.311      0.757          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.6it/s 0.2s\n",
      "                   all          3         19     0.0216          1      0.292      0.187\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50         0G     0.7348      1.429     0.7979          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9it/s 1.1s1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.6it/s 0.2s\n",
      "                   all          3         19     0.0216          1      0.338      0.201\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50         0G     0.7956       1.36     0.7933          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 0.9s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.0it/s 0.2s\n",
      "                   all          3         19     0.0216          1      0.338      0.201\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50         0G     0.7785      1.489     0.7852          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.8it/s 1.1s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.1it/s 0.2s\n",
      "                   all          3         19     0.0216          1      0.378      0.223\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50         0G     0.6945      1.107     0.7811          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9it/s 1.0s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.8it/s 0.2s\n",
      "                   all          3         19     0.0215          1      0.485      0.317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50         0G     0.7235      2.141     0.8108          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.8it/s 0.2s\n",
      "                   all          3         19     0.0215          1      0.485      0.317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50         0G     0.6537      1.163     0.7913         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.1s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.7it/s 0.2s\n",
      "                   all          3         19     0.0214          1      0.519      0.352\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50         0G      0.772      1.927     0.7868          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.2it/s 0.9s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.6it/s 0.2s\n",
      "                   all          3         19     0.0214          1      0.519      0.352\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50         0G     0.9443      1.387     0.7761          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9it/s 1.1s1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.5it/s 0.2s\n",
      "                   all          3         19      0.272      0.444      0.578      0.412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50         0G     0.8715      2.139     0.7987          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.2it/s 0.9s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.1it/s 0.2s\n",
      "                   all          3         19      0.272      0.444      0.578      0.412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50         0G     0.7481      2.071     0.7763          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 1.0s1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.0it/s 0.2s\n",
      "                   all          3         19      0.939       0.19      0.582      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50         0G     0.7184      1.765     0.7631          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.2it/s 0.9s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.2it/s 0.2s\n",
      "                   all          3         19      0.939       0.19      0.582      0.418\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50         0G     0.6543     0.9499      0.804          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9it/s 1.1s1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.0it/s 0.2s\n",
      "                   all          3         19      0.838      0.242      0.682      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50         0G     0.7515     0.9619     0.7692          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 0.9s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.6it/s 0.2s\n",
      "                   all          3         19      0.838      0.242      0.682      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50         0G     0.6414     0.9856     0.7831          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 1.0s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.1it/s 0.2s\n",
      "                   all          3         19      0.838      0.242      0.682      0.507\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50         0G     0.8789      1.602     0.8129          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9it/s 1.1s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.7it/s 0.2s\n",
      "                   all          3         19      0.685      0.517      0.773      0.606\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50         0G     0.8333       2.24     0.8232          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.6it/s 0.2s\n",
      "                   all          3         19      0.685      0.517      0.773      0.606\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50         0G     0.7581      2.117     0.8222          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 1.0s1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.0it/s 0.2s\n",
      "                   all          3         19      0.604      0.676      0.792      0.645\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50         0G     0.5951     0.9244     0.7483          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.2it/s 0.9s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.0it/s 0.2s\n",
      "                   all          3         19      0.604      0.676      0.792      0.645\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50         0G     0.8809      1.298     0.8388          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 1.0s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.3it/s 0.2s\n",
      "                   all          3         19      0.604      0.676      0.792      0.645\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50         0G      0.581      1.058     0.7932         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.0it/s 0.2s\n",
      "                   all          3         19      0.565      0.789      0.782      0.658\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50         0G     0.6859      1.739     0.7723          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.1it/s 0.2s\n",
      "                   all          3         19      0.565      0.789      0.782      0.658\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50         0G     0.5396     0.9101     0.8038          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.5it/s 0.2s\n",
      "                   all          3         19      0.565      0.789      0.782      0.658\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50         0G     0.6762      1.317      0.775          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.0it/s 0.2s\n",
      "                   all          3         19      0.578      0.743      0.814      0.703\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50         0G     0.6342     0.9024     0.8143          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.2it/s 0.9s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.6it/s 0.2s\n",
      "                   all          3         19      0.578      0.743      0.814      0.703\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50         0G     0.6582      1.218     0.7903          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.1it/s 0.2s\n",
      "                   all          3         19      0.578      0.743      0.814      0.703\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50         0G     0.5604     0.8985     0.7916          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.4it/s 0.2s\n",
      "                   all          3         19      0.764      0.807      0.869      0.738\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50         0G     0.5375      1.031     0.8199         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 0.9s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.6it/s 0.2s\n",
      "                   all          3         19      0.764      0.807      0.869      0.738\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50         0G     0.7221      1.091      0.791          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 1.0s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.3it/s 0.2s\n",
      "                   all          3         19      0.764      0.807      0.869      0.738\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50         0G     0.7102      1.077     0.7843          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.0it/s 0.2s\n",
      "                   all          3         19      0.743      0.826        0.9      0.765\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50         0G     0.5757      0.917     0.7798          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.8it/s 1.1s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.7it/s 0.3s\n",
      "                   all          3         19      0.743      0.826        0.9      0.765\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50         0G     0.7668       1.73      0.765          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 1.0s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.1it/s 0.2s\n",
      "                   all          3         19      0.743      0.826        0.9      0.765\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50         0G     0.6019     0.8591     0.7904          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.2it/s 0.9s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.5it/s 0.2s\n",
      "                   all          3         19      0.743      0.826        0.9      0.765\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50         0G     0.5513     0.8604     0.8078          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9it/s 1.0s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.7it/s 0.2s\n",
      "                   all          3         19      0.762      0.881       0.91      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50         0G     0.5807     0.8166      0.781          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 1.0s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.8it/s 0.2s\n",
      "                   all          3         19      0.762      0.881       0.91      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50         0G     0.7539      1.665      0.779          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 0.9s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.4it/s 0.2s\n",
      "                   all          3         19      0.762      0.881       0.91      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50         0G      0.668      1.186     0.7754          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.2it/s 0.9s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.1it/s 0.2s\n",
      "                   all          3         19      0.762      0.881       0.91      0.782\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50         0G     0.6056     0.8288     0.7776          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.2s1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.2it/s 0.2s\n",
      "                   all          3         19      0.811      0.921      0.927      0.802\n",
      "\n",
      "50 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_fp16\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_fp16\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_fp16\\weights\\best.pt...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.5it/s 0.2s\n",
      "                   all          3         19      0.812      0.924      0.927      0.802\n",
      "            light_blue          1          5      0.702          1      0.962      0.799\n",
      "             dark_blue          1          7      0.734      0.792      0.825      0.706\n",
      "                others          1          7          1       0.98      0.995      0.902\n",
      "Speed: 0.3ms preprocess, 27.2ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_fp16\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg1</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg2</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>metrics/mAP50(B)</td><td>â–â–â–â–â–â–â–â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–…â–…â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/mAP50-95(B)</td><td>â–â–â–â–â–â–â–â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/precision(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–ˆâ–ˆâ–‡â–‡â–†â–†â–…â–…â–…â–…â–…â–…â–…â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡</td></tr><tr><td>metrics/recall(B)</td><td>â–…â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ƒâ–â–â–â–â–„â–„â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡</td></tr><tr><td>model/GFLOPs</td><td>â–</td></tr><tr><td>model/parameters</td><td>â–</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>â–</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.92722</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.80243</td></tr><tr><td>metrics/precision(B)</td><td>0.81062</td></tr><tr><td>metrics/recall(B)</td><td>0.92065</td></tr><tr><td>model/GFLOPs</td><td>8.196</td></tr><tr><td>model/parameters</td><td>3011433</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>29.347</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolov8n_320_fp16</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/dgi1ex2v' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/dgi1ex2v</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 20 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_092041-dgi1ex2v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Running Validation...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 1.60.5 ms, read: 2.10.7 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3  0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.7it/s 0.1s\n",
      "                   all          3         19      0.812      0.924      0.927      0.802\n",
      "            light_blue          1          5      0.702          1      0.962      0.799\n",
      "             dark_blue          1          7      0.734      0.792      0.825      0.706\n",
      "                others          1          7          1       0.98      0.995      0.902\n",
      "Speed: 0.3ms preprocess, 28.2ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\runs\\detect\\val45\u001b[0m\n",
      "\n",
      "ğŸ“¦ Exporting to OpenVINO FP16...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_fp16\\weights\\best.pt' with input shape (1, 3, 320, 320) BCHW and output shape(s) (1, 7, 2100) (5.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2024.6.0-17404-4c0f47d2335-releases/2024/6...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success  5.4s, saved as 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_fp16\\weights\\best_openvino_model\\' (6.0 MB)\n",
      "\n",
      "Export complete (5.5s)\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_fp16\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_fp16\\weights\\best_openvino_model imgsz=320 half \n",
      "Validate:        yolo val task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_320_fp16\\weights\\best_openvino_model imgsz=320 data=../datasets/bottle_cap/data.yaml half \n",
      "Visualize:       https://netron.app\n",
      "â±ï¸ Running Benchmark on: Bottle-Cap-Detection\\yolov8n_320_fp16\\weights\\best_openvino_model\n",
      "Loading Bottle-Cap-Detection\\yolov8n_320_fp16\\weights\\best_openvino_model for OpenVINO inference...\n",
      "Using OpenVINO LATENCY mode for batch=1 inference on (CPU)...\n",
      "âœ… Speed Result (FP16): 10.05 ms (99.5 FPS)\n",
      "ğŸ”„ Re-connecting ke Run ID: dgi1ex2v...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_092249-dgi1ex2v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/dgi1ex2v' target=\"_blank\">yolov8n_320_fp16</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/dgi1ex2v' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/dgi1ex2v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data FP16 berhasil dikirim ke WandB!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>â–</td></tr><tr><td>inference/openvino_fp16_fps</td><td>â–</td></tr><tr><td>model/size_mb</td><td>â–</td></tr><tr><td>val/mAP50</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>10.05448</td></tr><tr><td>inference/openvino_fp16_fps</td><td>99.45817</td></tr><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.92722</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.80243</td></tr><tr><td>metrics/precision(B)</td><td>0.81062</td></tr><tr><td>metrics/recall(B)</td><td>0.92065</td></tr><tr><td>model/GFLOPs</td><td>8.196</td></tr><tr><td>+17</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolov8n_320_fp16</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/dgi1ex2v' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/dgi1ex2v</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_092249-dgi1ex2v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”’ WandB Session Closed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10.054478645324707"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Jalankan FP16 dengan Size 320\n",
    "run_experiment_fp16(\n",
    "    model_name='yolov8n.pt',       # atau 'yolo11n.pt'\n",
    "    exp_name='yolov8n_320_fp16', \n",
    "    img_size=320, \n",
    "    use_safe_aug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e004298",
   "metadata": {},
   "source": [
    "### Yolov8n 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6f290e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ START EXPERIMENT: yolov8n_256 | Size: 256 | Safe Aug: True\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_092253-p98elkuu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/p98elkuu' target=\"_blank\">yolov8n_256</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/p98elkuu' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/p98elkuu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›¡ï¸ Mengaktifkan SAFE MODE...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../datasets/bottle_cap/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=yolov8n_256, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=Bottle-Cap-Detection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_256, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.1, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "Model summary: 129 layers, 3,011,433 parameters, 3,011,417 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 2.40.8 ms, read: 2.00.2 MB/s, size: 52.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\train\\labels.cache... 9 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9  0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 2.10.8 ms, read: 1.90.4 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3  0.0s\n",
      "Plotting labels to G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_256\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_256\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50         0G      2.183      4.138     0.9994          5        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.2s1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.8it/s 0.2s\n",
      "                   all          3         19    0.00594      0.295    0.00705    0.00353\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50         0G      1.777      4.159     0.9728          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.2it/s 0.9s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.2it/s 0.2s\n",
      "                   all          3         19     0.0107      0.505     0.0156    0.00809\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50         0G      1.348      4.108     0.8503          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.3s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.6it/s 0.2s\n",
      "                   all          3         19     0.0125      0.552     0.0228     0.0108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50         0G      1.117      4.034     0.7865          5        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.3it/s 0.2s\n",
      "                   all          3         19     0.0157      0.667     0.0331    0.00918\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50         0G      1.225      3.845     0.8563          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9it/s 1.0s1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.1it/s 0.2s\n",
      "                   all          3         19     0.0186      0.762     0.0452     0.0113\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50         0G      1.471      3.781     0.8664          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.3it/s 0.9s1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.6it/s 0.2s\n",
      "                   all          3         19     0.0197       0.81     0.0474      0.015\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50         0G      1.518      3.617     0.8511          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.1it/s 0.9s1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.7it/s 0.2s\n",
      "                   all          3         19     0.0212      0.905     0.0571     0.0245\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50         0G      1.333      3.427     0.8293          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.8it/s 0.2s\n",
      "                   all          3         19     0.0212      0.905     0.0531     0.0326\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50         0G      1.003      3.327     0.8375          5        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.2s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8it/s 0.3s\n",
      "                   all          3         19     0.0211      0.905     0.0528     0.0386\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50         0G     0.8583      2.904     0.7933         10        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0it/s 1.0s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.8it/s 0.2s\n",
      "                   all          3         19     0.0225          1     0.0562     0.0413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50         0G     0.9201      2.716     0.7921          6        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.9it/s 0.2s\n",
      "                   all          3         19     0.0221          1     0.0583     0.0423\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50         0G      1.148      2.104     0.8262          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.8it/s 0.7s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.4it/s 0.2s\n",
      "                   all          3         19     0.0221          1     0.0583     0.0423\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50         0G      0.987      2.548     0.7824          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.5it/s 0.8s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.0it/s 0.2s\n",
      "                   all          3         19     0.0218          1     0.0623     0.0413\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50         0G     0.8433      1.882      0.821          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.4it/s 0.8s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.1it/s 0.2s\n",
      "                   all          3         19     0.0217          1      0.233      0.121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50         0G     0.8342      1.621     0.8205          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.5it/s 0.8s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.8it/s 0.1s\n",
      "                   all          3         19     0.0217          1      0.233      0.121\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50         0G      1.035      1.524     0.8074          3        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.8it/s 0.7s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.6it/s 0.2s\n",
      "                   all          3         19     0.0216          1      0.299      0.193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50         0G     0.7708      1.237     0.8003          6        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.6it/s 0.8s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.0it/s 0.1s\n",
      "                   all          3         19     0.0215          1      0.343      0.252\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50         0G     0.8638      1.976     0.7684          5        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.9it/s 0.7s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.0it/s 0.2s\n",
      "                   all          3         19     0.0215          1      0.343      0.252\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50         0G     0.7657      1.378     0.7755         10        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.3it/s 0.2s\n",
      "                   all          3         19     0.0214          1      0.435      0.323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50         0G     0.8307      2.015      0.773          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.8it/s 0.7s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.0it/s 0.1s\n",
      "                   all          3         19     0.0214          1      0.435      0.323\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50         0G     0.9855      1.524     0.8135          3        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.5it/s 0.8s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.6it/s 0.2s\n",
      "                   all          3         19     0.0213          1      0.484       0.36\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50         0G     0.9404       2.12     0.7819          6        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.2it/s 0.6s0.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.4it/s 0.2s\n",
      "                   all          3         19     0.0213          1      0.484       0.36\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50         0G     0.8288      1.962      0.757          6        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.8s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.9it/s 0.1s\n",
      "                   all          3         19     0.0213          1      0.555      0.433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50         0G     0.8058      1.655     0.7593          5        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.8s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.2it/s 0.2s\n",
      "                   all          3         19     0.0213          1      0.555      0.433\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50         0G     0.7813     0.9754     0.8247          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.6it/s 0.8s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.6it/s 0.1s\n",
      "                   all          3         19     0.0552          1       0.57      0.424\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50         0G     0.7127      1.034     0.7722          9        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.8it/s 0.7s0.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.6it/s 0.2s\n",
      "                   all          3         19     0.0552          1       0.57      0.424\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50         0G     0.6694     0.9715     0.8014          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.9it/s 0.7s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.6it/s 0.2s\n",
      "                   all          3         19     0.0552          1       0.57      0.424\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50         0G      1.067      1.652     0.8611          5        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.6it/s 0.8s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.4it/s 0.1s\n",
      "                   all          3         19      0.717      0.299      0.615      0.458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50         0G     0.8035      2.174     0.7925          6        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.9it/s 0.7s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.3it/s 0.2s\n",
      "                   all          3         19      0.717      0.299      0.615      0.458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50         0G     0.9224      2.055     0.7342          6        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.7it/s 0.7s0.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 6.8it/s 0.1s\n",
      "                   all          3         19       0.72      0.235      0.712      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50         0G     0.6354     0.9537     0.7763          8        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.1it/s 0.7s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.0it/s 0.1s\n",
      "                   all          3         19       0.72      0.235      0.712      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50         0G     0.8492      1.204     0.8525          3        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 3.0it/s 0.7s0.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 7.0it/s 0.1s\n",
      "                   all          3         19       0.72      0.235      0.712      0.515\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50         0G     0.7039      1.031     0.7574         10        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.3s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
      "                   all          3         19      0.741      0.333       0.74      0.566\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50         0G     0.7326      1.735     0.7708          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19      0.741      0.333       0.74      0.566\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50         0G     0.6798     0.9912     0.7996          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19      0.741      0.333       0.74      0.566\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50         0G      0.829      1.359     0.7763          5        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19      0.632      0.547      0.757       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50         0G     0.6308     0.9048     0.7849          9        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.2s1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.7it/s 0.3s\n",
      "                   all          3         19      0.632      0.547      0.757       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50         0G     0.7341      1.256     0.8195          5        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9it/s 1.0s1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.6it/s 0.2s\n",
      "                   all          3         19      0.632      0.547      0.757       0.62\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50         0G     0.6093     0.9476     0.7505          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.2s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.9it/s 0.2s\n",
      "                   all          3         19       0.58      0.731      0.771      0.664\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50         0G     0.5129      0.974     0.8067         10        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.2s1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.7it/s 0.2s\n",
      "                   all          3         19       0.58      0.731      0.771      0.664\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50         0G     0.7745       1.07     0.7732          3        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.3s1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.7it/s 0.3s\n",
      "                   all          3         19       0.58      0.731      0.771      0.664\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50         0G     0.6899       1.06     0.7545          3        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.6it/s 0.2s\n",
      "                   all          3         19      0.482      0.933      0.832      0.704\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50         0G     0.6586      0.892     0.7845          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.2s1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.3it/s 0.2s\n",
      "                   all          3         19      0.482      0.933      0.832      0.704\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50         0G        0.8      1.799     0.8089          6        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.2s1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.7it/s 0.3s\n",
      "                   all          3         19      0.482      0.933      0.832      0.704\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50         0G     0.6247     0.8383     0.7545          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.8it/s 1.1s1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.2it/s 0.2s\n",
      "                   all          3         19      0.482      0.933      0.832      0.704\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50         0G      0.598     0.8135     0.8416          8        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.3s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6it/s 0.3s\n",
      "                   all          3         19      0.657      0.933      0.882       0.75\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50         0G     0.6379     0.9082     0.7554          8        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.2s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.0it/s 0.2s\n",
      "                   all          3         19      0.657      0.933      0.882       0.75\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50         0G     0.7834      1.638     0.7897          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.8it/s 1.1s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.2it/s 0.2s\n",
      "                   all          3         19      0.657      0.933      0.882       0.75\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50         0G     0.6748      1.301     0.8285          5        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.2s1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.0it/s 0.3s\n",
      "                   all          3         19      0.657      0.933      0.882       0.75\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50         0G     0.6854     0.8667     0.7883          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.2s1.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.3it/s 0.2s\n",
      "                   all          3         19      0.834       0.89      0.931      0.788\n",
      "\n",
      "50 epochs completed in 0.024 hours.\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_256\\weights\\last.pt, 6.2MB\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_256\\weights\\best.pt, 6.2MB\n",
      "\n",
      "Validating G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_256\\weights\\best.pt...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
      "                   all          3         19       0.84      0.886      0.933      0.789\n",
      "            light_blue          1          5          1      0.657      0.872      0.727\n",
      "             dark_blue          1          7      0.577          1      0.933      0.824\n",
      "                others          1          7      0.943          1      0.995      0.817\n",
      "Speed: 0.4ms preprocess, 56.7ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_256\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg1</td><td>â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg2</td><td>â–â–‚â–ƒâ–ƒâ–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>metrics/mAP50(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/mAP50-95(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/precision(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–…â–…â–…â–†â–†â–†â–ˆ</td></tr><tr><td>metrics/recall(B)</td><td>â–‚â–ƒâ–„â–…â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–‚â–â–â–‚â–‚â–‚â–„â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡</td></tr><tr><td>model/GFLOPs</td><td>â–</td></tr><tr><td>model/parameters</td><td>â–</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>â–</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.9314</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.78792</td></tr><tr><td>metrics/precision(B)</td><td>0.83418</td></tr><tr><td>metrics/recall(B)</td><td>0.88987</td></tr><tr><td>model/GFLOPs</td><td>8.196</td></tr><tr><td>model/parameters</td><td>3011433</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>37.037</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolov8n_256</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/p98elkuu' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/p98elkuu</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 20 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_092253-p98elkuu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Running Validation...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "Model summary (fused): 72 layers, 3,006,233 parameters, 0 gradients, 8.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 1.50.4 ms, read: 2.30.9 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.5Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 5.9it/s 0.2s\n",
      "                   all          3         19       0.84      0.886      0.933      0.789\n",
      "            light_blue          1          5          1      0.657      0.872      0.727\n",
      "             dark_blue          1          7      0.577          1      0.933      0.824\n",
      "                others          1          7      0.943          1      0.995      0.817\n",
      "Speed: 0.3ms preprocess, 36.1ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\runs\\detect\\val46\u001b[0m\n",
      "ğŸ“¦ Exporting to ONNX...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_256\\weights\\best.pt' with input shape (1, 3, 256, 256) BCHW and output shape(s) (1, 7, 1344) (5.9 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.74...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.9s, saved as 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_256\\weights\\best.onnx' (11.6 MB)\n",
      "\n",
      "Export complete (2.1s)\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_256\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_256\\weights\\best.onnx imgsz=256  \n",
      "Validate:        yolo val task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov8n_256\\weights\\best.onnx imgsz=256 data=../datasets/bottle_cap/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "â±ï¸ Running Benchmark on: Bottle-Cap-Detection\\yolov8n_256\\weights\\best.onnx\n",
      "âœ… Speed Result: 35.57 ms (28.1 FPS)\n",
      "ğŸ”„ Re-connecting ke Run ID: p98elkuu...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_092500-p98elkuu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/p98elkuu' target=\"_blank\">yolov8n_256</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/p98elkuu' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/p98elkuu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data benchmark berhasil dikirim ke WandB!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>â–</td></tr><tr><td>inference/onnx_fps</td><td>â–</td></tr><tr><td>model/size_mb</td><td>â–</td></tr><tr><td>val/mAP50</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>35.56535</td></tr><tr><td>inference/onnx_fps</td><td>28.11725</td></tr><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.9314</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.78792</td></tr><tr><td>metrics/precision(B)</td><td>0.83418</td></tr><tr><td>metrics/recall(B)</td><td>0.88987</td></tr><tr><td>model/GFLOPs</td><td>8.196</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolov8n_256</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/p98elkuu' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/p98elkuu</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_092500-p98elkuu\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”’ Sesi WandB ditutup.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "35.56535243988037"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Coba Size 256 (Sweet Spot?)\n",
    "run_experiment(\n",
    "    model_name='yolov8n.pt',  # Pastikan ini menunjuk ke checkpoint terbaikmu\n",
    "    exp_name='yolov8n_256',\n",
    "    img_size=256,             # <--- Turunkan resolusi\n",
    "    use_safe_aug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891b0859",
   "metadata": {},
   "source": [
    "## YOLOv10n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "981dd938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ START EXPERIMENT: yolov10n_320 | Size: 320 | Safe Aug: False\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_092504-ktthsvkv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ktthsvkv' target=\"_blank\">yolov10n_320</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ktthsvkv' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ktthsvkv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../datasets/bottle_cap/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov10n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov10n_320, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=Bottle-Cap-Detection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov10n_320, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n",
      " 23        [16, 19, 22]  1    862498  ultralytics.nn.modules.head.v10Detect        [3, [64, 128, 256]]           \n",
      "YOLOv10n summary: 223 layers, 2,708,210 parameters, 2,708,194 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 493/595 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 2.00.4 ms, read: 2.50.6 MB/s, size: 52.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\train\\labels.cache... 9 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.9Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 1.70.7 ms, read: 2.20.5 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.5Kit/s 0.0s\n",
      "Plotting labels to G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov10n_320\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.0005), 107 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov10n_320\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50         0G      2.785      8.296      1.843          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.1s3.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "                   all          3         19          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50         0G      2.556      8.331      1.802          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s3.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50         0G      2.718      8.393      1.693         18        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3s/it 2.5s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19          0          0          0          0\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50         0G       1.92      7.983      1.696          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3s/it 2.6s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19    0.00109     0.0476   0.000625   6.25e-05\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50         0G      2.448      7.899      1.743          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2s/it 2.3s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.3s\n",
      "                   all          3         19    0.00109     0.0476   0.000625    0.00025\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50         0G      2.204       7.82      1.664         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1s/it 2.3s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19    0.00109     0.0476   0.000626     0.0005\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50         0G      2.353      7.865      1.644         24        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2s/it 2.3s2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
      "                   all          3         19    0.00109     0.0476   0.000627   0.000376\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50         0G       2.13      7.357      1.635          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2s/it 2.4s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19    0.00331      0.143    0.00205    0.00128\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50         0G      2.662      7.748      1.671         24        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2s/it 2.3s2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.3s\n",
      "                   all          3         19    0.00331      0.143    0.00205    0.00142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50         0G      2.159      7.402      1.649         17        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2s/it 2.5s2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19    0.00331      0.143    0.00205    0.00142\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50         0G      1.901      6.732       1.65          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3s/it 2.7s3.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19    0.00221     0.0952    0.00126   0.000885\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50         0G       2.23      6.799      1.531          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2s/it 2.4s2.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19    0.00221     0.0952    0.00126   0.000885\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50         0G      2.375      6.874      1.632          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2s/it 2.4s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
      "                   all          3         19    0.00331      0.143    0.00205    0.00136\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50         0G      1.957      6.778      1.584         16        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3s/it 2.7s3.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.3s\n",
      "                   all          3         19     0.0044       0.19    0.00298    0.00216\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50         0G      1.901      6.625      1.593         14        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1s/it 2.3s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19     0.0044       0.19    0.00298    0.00216\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50         0G      2.319      6.826      1.576         21        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3s/it 2.5s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19    0.00327      0.143    0.00234     0.0017\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50         0G      2.289      6.309      1.674         21        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1s/it 2.1s2.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
      "                   all          3         19    0.00327      0.143    0.00234    0.00161\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50         0G      1.736      5.699      1.557         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19    0.00327      0.143    0.00234    0.00161\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50         0G      2.302      5.882      1.609         22        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.6s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.0it/s 0.3s\n",
      "                   all          3         19    0.00327      0.143    0.00234     0.0017\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50         0G      1.786      4.606      1.569          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.7it/s 0.3s\n",
      "                   all          3         19    0.00327      0.143    0.00234     0.0017\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50         0G      1.923      5.718      1.655          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19    0.00327      0.143    0.00235    0.00171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50         0G      1.879      5.532      1.583          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19    0.00327      0.143    0.00235    0.00171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50         0G      2.235      5.172      1.668          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.4it/s 0.2s\n",
      "                   all          3         19    0.00545      0.238      0.112     0.0811\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50         0G      1.777       4.16      1.668          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.5s1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.9it/s 0.3s\n",
      "                   all          3         19    0.00545      0.238      0.112     0.0811\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50         0G      2.022       5.38      1.607          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.9it/s 0.3s\n",
      "                   all          3         19    0.00769      0.333      0.202      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50         0G      2.126      5.398      1.583         11        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.5s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.9it/s 0.3s\n",
      "                   all          3         19    0.00769      0.333      0.202      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50         0G      2.933      4.586      1.634          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6it/s 0.3s\n",
      "                   all          3         19    0.00769      0.333      0.202      0.155\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50         0G      2.084      5.042      1.606         19        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.1it/s 0.3s\n",
      "                   all          3         19     0.0111      0.476      0.312      0.237\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50         0G      1.992      4.805      1.641         22        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.4s1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.0it/s 0.2s\n",
      "                   all          3         19     0.0111      0.476      0.312      0.237\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50         0G       1.97      5.281      1.634         21        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19     0.0134       0.59      0.332       0.24\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50         0G      1.899      4.619      1.626         15        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.7it/s 0.3s\n",
      "                   all          3         19     0.0134       0.59      0.332       0.24\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50         0G       1.86      4.595      1.592         15        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.5s1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19     0.0134       0.59      0.332       0.24\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50         0G      1.941      4.825      1.636          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.4it/s 0.7s\n",
      "                   all          3         19     0.0145      0.657      0.387      0.262\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50         0G       1.96       4.28      1.712          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 2.0s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19     0.0145      0.657      0.387      0.262\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50         0G      2.132      4.989      1.704          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.1it/s 0.3s\n",
      "                   all          3         19     0.0145      0.657      0.387      0.262\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50         0G      1.766      4.053      1.585         15        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.6s1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19     0.0189      0.905      0.497       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50         0G      1.791      3.312      1.626          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.4s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.9it/s 0.3s\n",
      "                   all          3         19     0.0189      0.905      0.497       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50         0G      1.722       3.47      1.605          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.1it/s 0.2s\n",
      "                   all          3         19     0.0189      0.905      0.497       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50         0G      2.659       4.21      1.686         16        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.1it/s 0.2s\n",
      "                   all          3         19     0.0189      0.905      0.565       0.39\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50         0G       1.76      4.396      1.645         25        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.5s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
      "                   all          3         19     0.0189      0.905      0.565       0.39\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50         0G      1.895      3.823       1.65          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.0it/s 0.2s\n",
      "                   all          3         19     0.0189      0.905      0.565       0.39\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50         0G      1.881      3.103      1.569          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.5it/s 0.3s\n",
      "                   all          3         19     0.0211          1      0.571      0.412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50         0G      1.645      2.968      1.668          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.2it/s 0.2s\n",
      "                   all          3         19     0.0211          1      0.571      0.412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50         0G      1.939       4.22      1.604          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1s/it 2.1s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19     0.0211          1      0.571      0.412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50         0G      1.737      2.893      1.596          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2s/it 2.4s2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19     0.0211          1      0.571      0.412\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50         0G      1.448      2.887       1.59          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1s/it 2.2s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19      0.869      0.147      0.622      0.466\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50         0G      1.353      2.723      1.547          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.0s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19      0.869      0.147      0.622      0.466\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50         0G       1.41      3.591      1.549          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.0s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
      "                   all          3         19      0.869      0.147      0.622      0.466\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50         0G      1.575      3.995      1.553          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.0s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "                   all          3         19      0.869      0.147      0.622      0.466\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50         0G      1.555      2.853      1.576          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1s/it 2.2s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19      0.892        0.2      0.666      0.506\n",
      "\n",
      "50 epochs completed in 0.041 hours.\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov10n_320\\weights\\last.pt, 5.3MB\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov10n_320\\weights\\best.pt, 5.3MB\n",
      "\n",
      "Validating G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov10n_320\\weights\\best.pt...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "YOLOv10n summary (fused): 102 layers, 2,265,753 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19      0.891      0.198      0.666      0.506\n",
      "            light_blue          1          5          1          0      0.415      0.313\n",
      "             dark_blue          1          7          1          0      0.735      0.489\n",
      "                others          1          7      0.674      0.594       0.85      0.715\n",
      "Speed: 0.6ms preprocess, 56.5ms inference, 0.0ms loss, 0.2ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov10n_320\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–„â–ƒâ–‚</td></tr><tr><td>lr/pg1</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg2</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>metrics/mAP50(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/mAP50-95(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–ˆ</td></tr><tr><td>metrics/precision(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/recall(B)</td><td>â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–‚â–‚â–‚</td></tr><tr><td>model/GFLOPs</td><td>â–</td></tr><tr><td>model/parameters</td><td>â–</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>â–</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.66643</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.50576</td></tr><tr><td>metrics/precision(B)</td><td>0.89199</td></tr><tr><td>metrics/recall(B)</td><td>0.19978</td></tr><tr><td>model/GFLOPs</td><td>8.397</td></tr><tr><td>model/parameters</td><td>2708210</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>95.437</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolov10n_320</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ktthsvkv' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ktthsvkv</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 20 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_092504-ktthsvkv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Running Validation...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "YOLOv10n summary (fused): 102 layers, 2,265,753 parameters, 0 gradients, 6.5 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 1.60.5 ms, read: 1.80.7 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.0Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.1it/s 0.2s\n",
      "                   all          3         19      0.891      0.198      0.666      0.506\n",
      "            light_blue          1          5          1          0      0.415      0.313\n",
      "             dark_blue          1          7          1          0      0.735      0.489\n",
      "                others          1          7      0.674      0.594       0.85      0.715\n",
      "Speed: 0.3ms preprocess, 61.0ms inference, 0.0ms loss, 0.1ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\runs\\detect\\val47\u001b[0m\n",
      "ğŸ“¦ Exporting to ONNX...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov10n_320\\weights\\best.pt' with input shape (1, 3, 320, 320) BCHW and output shape(s) (1, 300, 6) (5.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.74...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.1s, saved as 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov10n_320\\weights\\best.onnx' (8.8 MB)\n",
      "\n",
      "Export complete (2.4s)\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov10n_320\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov10n_320\\weights\\best.onnx imgsz=320  \n",
      "Validate:        yolo val task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov10n_320\\weights\\best.onnx imgsz=320 data=../datasets/bottle_cap/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "â±ï¸ Running Benchmark on: Bottle-Cap-Detection\\yolov10n_320\\weights\\best.onnx\n",
      "âœ… Speed Result: 34.96 ms (28.6 FPS)\n",
      "ğŸ”„ Re-connecting ke Run ID: ktthsvkv...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_092814-ktthsvkv</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ktthsvkv' target=\"_blank\">yolov10n_320</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ktthsvkv' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ktthsvkv</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data benchmark berhasil dikirim ke WandB!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>â–</td></tr><tr><td>inference/onnx_fps</td><td>â–</td></tr><tr><td>model/size_mb</td><td>â–</td></tr><tr><td>val/mAP50</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>34.95661</td></tr><tr><td>inference/onnx_fps</td><td>28.60689</td></tr><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.66643</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.50576</td></tr><tr><td>metrics/precision(B)</td><td>0.89199</td></tr><tr><td>metrics/recall(B)</td><td>0.19978</td></tr><tr><td>model/GFLOPs</td><td>8.397</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolov10n_320</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ktthsvkv' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ktthsvkv</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_092814-ktthsvkv\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”’ Sesi WandB ditutup.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34.9566125869751"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jalankan Eksperimen 1: Ukuran 320, Augmentasi Aman\n",
    "run_experiment(\n",
    "    model_name='yolov10n.pt', \n",
    "    exp_name='yolov10n_320', \n",
    "    img_size=320, \n",
    "    use_safe_aug=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e264bb5b",
   "metadata": {},
   "source": [
    "## YOLO9t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e02a6d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ START EXPERIMENT: yolov9t_320 | Size: 320 | Safe Aug: False\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_092818-ewfwac0g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ewfwac0g' target=\"_blank\">yolov9t_320</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ewfwac0g' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ewfwac0g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../datasets/bottle_cap/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov9t.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolov9t_320, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=Bottle-Cap-Detection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7872  ultralytics.nn.modules.block.ELAN1           [32, 32, 32, 16]              \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.block.AConv           [32, 64]                      \n",
      "  4                  -1  1     65216  ultralytics.nn.modules.block.RepNCSPELAN4    [64, 64, 64, 32, 3]           \n",
      "  5                  -1  1     55488  ultralytics.nn.modules.block.AConv           [64, 96]                      \n",
      "  6                  -1  1    145824  ultralytics.nn.modules.block.RepNCSPELAN4    [96, 96, 96, 48, 3]           \n",
      "  7                  -1  1    110848  ultralytics.nn.modules.block.AConv           [96, 128]                     \n",
      "  8                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  9                  -1  1     41344  ultralytics.nn.modules.block.SPPELAN         [128, 128, 64]                \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    158112  ultralytics.nn.modules.block.RepNCSPELAN4    [224, 96, 96, 48, 3]          \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     71360  ultralytics.nn.modules.block.RepNCSPELAN4    [160, 64, 64, 32, 3]          \n",
      " 16                  -1  1     27744  ultralytics.nn.modules.block.AConv           [64, 48]                      \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    150432  ultralytics.nn.modules.block.RepNCSPELAN4    [144, 96, 96, 48, 3]          \n",
      " 19                  -1  1     55424  ultralytics.nn.modules.block.AConv           [96, 64]                      \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    266624  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 128, 128, 64, 3]        \n",
      " 22        [15, 18, 21]  1    567577  ultralytics.nn.modules.head.Detect           [3, [64, 96, 128]]            \n",
      "YOLOv9t summary: 544 layers, 2,005,993 parameters, 2,005,977 gradients, 7.9 GFLOPs\n",
      "\n",
      "Transferred 1303/1339 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 1.80.5 ms, read: 2.60.6 MB/s, size: 52.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\train\\labels.cache... 9 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 5.9Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 1.70.9 ms, read: 2.20.7 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 603.2it/s 0.0s\n",
      "Plotting labels to G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 221 weight(decay=0.0), 228 weight(decay=0.0005), 227 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50         0G      1.893      4.194      1.031          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9s/it 3.7s3.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
      "                   all          3         19    0.00268      0.143    0.00246   0.000981\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50         0G      1.624       4.06     0.9735          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.8s/it 3.5s3.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19    0.00447      0.238    0.00408    0.00145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50         0G      1.615      4.036     0.8958         18        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.8s/it 3.5s3.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.5s\n",
      "                   all          3         19    0.00549      0.286    0.00554   0.000872\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50         0G     0.8807      3.841     0.8595          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.3s3.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19    0.00453      0.238    0.00386   0.000819\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50         0G      1.027      4.038     0.8357          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.6s\n",
      "                   all          3         19    0.00769      0.352     0.0119    0.00284\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50         0G      1.206      3.649     0.8524         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s4.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
      "                   all          3         19    0.00862        0.4     0.0151    0.00483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50         0G      1.414      3.537     0.8447         24        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.6it/s 0.6s\n",
      "                   all          3         19     0.0119      0.514     0.0224     0.0104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50         0G      1.121      3.216     0.8542          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.4s3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.2it/s 0.8s\n",
      "                   all          3         19     0.0189      0.762     0.0413     0.0199\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50         0G      1.341      3.091     0.8394         24        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9s/it 3.7s4.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.5it/s 0.6s\n",
      "                   all          3         19     0.0207      0.905     0.0679     0.0414\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50         0G      1.065      2.897     0.8319         17        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.3s3.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.5it/s 0.7s\n",
      "                   all          3         19     0.0222          1     0.0734     0.0505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50         0G     0.8631      2.297     0.8487          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.1s3.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.2it/s 0.8s\n",
      "                   all          3         19     0.0221          1     0.0833      0.056\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50         0G      1.075      1.737     0.7926          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.5s\n",
      "                   all          3         19     0.0221          1     0.0833      0.056\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50         0G      0.952       1.95     0.7982          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.1s2.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19     0.0219          1     0.0825     0.0575\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50         0G     0.8649       2.19     0.8072         16        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.8s/it 3.6s4.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19     0.0217          1      0.293      0.188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50         0G      0.943      2.436     0.8132         14        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3s/it 2.7s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19     0.0217          1      0.293      0.188\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50         0G       1.02      2.523     0.8025         21        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.4s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19     0.0216          1      0.388      0.246\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50         0G      1.049      1.786     0.8375         21        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s3.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.6s\n",
      "                   all          3         19     0.0215          1      0.412       0.25\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50         0G     0.8867      1.669     0.7679         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19     0.0215          1      0.412       0.25\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50         0G      1.139      1.546     0.8043         22        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.4s4.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.4it/s 0.7s\n",
      "                   all          3         19      0.599      0.381      0.404      0.263\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50         0G     0.7168      1.122     0.8113          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.5s\n",
      "                   all          3         19      0.599      0.381      0.404      0.263\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50         0G      1.112      3.146      0.842          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s3.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19       0.63      0.333      0.422      0.283\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50         0G     0.7343      1.697      0.823          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19       0.63      0.333      0.422      0.283\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50         0G      1.049      1.768     0.8363          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s3.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19      0.603       0.57      0.526      0.332\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50         0G     0.7103      1.135     0.8475          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19      0.603       0.57      0.526      0.332\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50         0G     0.8612      1.858     0.8367          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.1s3.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19      0.745      0.476      0.639       0.43\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50         0G     0.9591      1.747        0.8         11        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.9s2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19      0.745      0.476      0.639       0.43\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50         0G      1.301      1.626     0.8342          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 2.9s3.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19      0.745      0.476      0.639       0.43\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50         0G     0.9591      1.662     0.7913         19        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s2.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19          1      0.209      0.708       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50         0G     0.9508      1.552     0.8118         22        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s3.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19          1      0.209      0.708       0.53\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50         0G     0.9988       1.85     0.8272         21        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.4s4.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.5s\n",
      "                   all          3         19          1      0.232      0.724      0.552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50         0G     0.9188      1.336     0.8477         15        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s3.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19          1      0.232      0.724      0.552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50         0G     0.8356      1.242     0.8098         15        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.5s3.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.3it/s 0.8s\n",
      "                   all          3         19          1      0.232      0.724      0.552\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50         0G      1.029      1.814     0.8307          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.3s2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.5it/s 0.7s\n",
      "                   all          3         19      0.865      0.287       0.78      0.609\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50         0G     0.7781      1.239     0.8278          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
      "                   all          3         19      0.865      0.287       0.78      0.609\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50         0G      1.051      2.345     0.8578          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.9s2.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.6s\n",
      "                   all          3         19      0.865      0.287       0.78      0.609\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50         0G     0.7195      1.271     0.7969         15        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.1s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.6s\n",
      "                   all          3         19      0.855      0.634      0.861        0.7\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50         0G     0.6509      1.039     0.8253          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19      0.855      0.634      0.861        0.7\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50         0G     0.6672      1.058     0.7463          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.1s2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19      0.855      0.634      0.861        0.7\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50         0G      1.116      1.062     0.8107         16        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19        0.8      0.762      0.932      0.764\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50         0G     0.8289      1.366     0.8273         25        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19        0.8      0.762      0.932      0.764\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50         0G      0.835      1.565     0.8475          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s3.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19        0.8      0.762      0.932      0.764\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50         0G     0.6068      1.042     0.6924          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.4s4.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19      0.777      0.772      0.959      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50         0G     0.6036      1.031     0.7992          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.9s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19      0.777      0.772      0.959      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50         0G     0.8206      1.407     0.8015          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.9s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19      0.777      0.772      0.959      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50         0G     0.6574     0.9726     0.7771          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 2.9s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.6it/s 0.6s\n",
      "                   all          3         19      0.777      0.772      0.959      0.798\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50         0G     0.5508     0.9317     0.8197          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.5s\n",
      "                   all          3         19      0.771      0.824      0.962      0.803\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50         0G     0.5488     0.8735      0.786          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.9s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19      0.771      0.824      0.962      0.803\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50         0G     0.6011      1.262     0.7556          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19      0.771      0.824      0.962      0.803\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50         0G     0.8743      2.769     0.8069          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3s/it 2.7s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
      "                   all          3         19      0.771      0.824      0.962      0.803\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50         0G     0.6833     0.9774     0.7891          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s2.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19      0.724      0.848      0.965      0.808\n",
      "\n",
      "50 epochs completed in 0.069 hours.\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320\\weights\\last.pt, 4.5MB\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320\\weights\\best.pt, 4.5MB\n",
      "\n",
      "Validating G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320\\weights\\best.pt...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "YOLOv9t summary (fused): 197 layers, 1,971,369 parameters, 0 gradients, 7.6 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19      0.723      0.848      0.965      0.807\n",
      "            light_blue          1          5      0.304          1      0.995      0.868\n",
      "             dark_blue          1          7      0.866      0.714      0.905      0.673\n",
      "                others          1          7          1      0.831      0.995      0.882\n",
      "Speed: 0.6ms preprocess, 80.1ms inference, 0.0ms loss, 1.5ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg1</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg2</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>metrics/mAP50(B)</td><td>â–â–â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–„â–„â–„â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/mAP50-95(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–†â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/precision(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–…â–…â–…â–…â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–†â–†â–†â–†â–†â–†</td></tr><tr><td>metrics/recall(B)</td><td>â–â–‚â–‚â–‚â–ƒâ–†â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡</td></tr><tr><td>model/GFLOPs</td><td>â–</td></tr><tr><td>model/parameters</td><td>â–</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>â–</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.965</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.80777</td></tr><tr><td>metrics/precision(B)</td><td>0.72386</td></tr><tr><td>metrics/recall(B)</td><td>0.84849</td></tr><tr><td>model/GFLOPs</td><td>7.851</td></tr><tr><td>model/parameters</td><td>2005993</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>140.423</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolov9t_320</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ewfwac0g' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ewfwac0g</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 20 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_092818-ewfwac0g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Running Validation...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "YOLOv9t summary (fused): 197 layers, 1,971,369 parameters, 0 gradients, 7.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 2.00.8 ms, read: 1.90.4 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.5Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19      0.723      0.848      0.965      0.807\n",
      "            light_blue          1          5      0.304          1      0.995      0.868\n",
      "             dark_blue          1          7      0.866      0.714      0.905      0.673\n",
      "                others          1          7          1      0.831      0.995      0.882\n",
      "Speed: 0.3ms preprocess, 95.8ms inference, 0.0ms loss, 1.6ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\runs\\detect\\val48\u001b[0m\n",
      "ğŸ“¦ Exporting to ONNX...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320\\weights\\best.pt' with input shape (1, 3, 320, 320) BCHW and output shape(s) (1, 7, 2100) (4.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.74...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  4.8s, saved as 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320\\weights\\best.onnx' (7.8 MB)\n",
      "\n",
      "Export complete (5.4s)\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320\\weights\\best.onnx imgsz=320  \n",
      "Validate:        yolo val task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320\\weights\\best.onnx imgsz=320 data=../datasets/bottle_cap/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "â±ï¸ Running Benchmark on: Bottle-Cap-Detection\\yolov9t_320\\weights\\best.onnx\n",
      "âœ… Speed Result: 46.07 ms (21.7 FPS)\n",
      "ğŸ”„ Re-connecting ke Run ID: ewfwac0g...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_093315-ewfwac0g</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ewfwac0g' target=\"_blank\">yolov9t_320</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ewfwac0g' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ewfwac0g</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data benchmark berhasil dikirim ke WandB!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>â–</td></tr><tr><td>inference/onnx_fps</td><td>â–</td></tr><tr><td>model/size_mb</td><td>â–</td></tr><tr><td>val/mAP50</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>46.06809</td></tr><tr><td>inference/onnx_fps</td><td>21.707</td></tr><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.965</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.80777</td></tr><tr><td>metrics/precision(B)</td><td>0.72386</td></tr><tr><td>metrics/recall(B)</td><td>0.84849</td></tr><tr><td>model/GFLOPs</td><td>7.851</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolov9t_320</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ewfwac0g' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/ewfwac0g</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_093315-ewfwac0g\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”’ Sesi WandB ditutup.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46.06808662414551"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jalankan Eksperimen 1: Ukuran 320, Augmentasi Aman\n",
    "run_experiment(\n",
    "    model_name='yolov9t.pt', \n",
    "    exp_name='yolov9t_320', \n",
    "    img_size=320, \n",
    "    use_safe_aug=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd60711",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "12f90d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ START EXPERIMENT: yolov9t_320_aug | Size: 320 | Safe Aug: True\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_093319-48mcxl4v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/48mcxl4v' target=\"_blank\">yolov9t_320_aug</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/48mcxl4v' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/48mcxl4v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›¡ï¸ Mengaktifkan SAFE MODE...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../datasets/bottle_cap/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov9t.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=yolov9t_320_aug, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=Bottle-Cap-Detection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_aug, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.1, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7872  ultralytics.nn.modules.block.ELAN1           [32, 32, 32, 16]              \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.block.AConv           [32, 64]                      \n",
      "  4                  -1  1     65216  ultralytics.nn.modules.block.RepNCSPELAN4    [64, 64, 64, 32, 3]           \n",
      "  5                  -1  1     55488  ultralytics.nn.modules.block.AConv           [64, 96]                      \n",
      "  6                  -1  1    145824  ultralytics.nn.modules.block.RepNCSPELAN4    [96, 96, 96, 48, 3]           \n",
      "  7                  -1  1    110848  ultralytics.nn.modules.block.AConv           [96, 128]                     \n",
      "  8                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  9                  -1  1     41344  ultralytics.nn.modules.block.SPPELAN         [128, 128, 64]                \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    158112  ultralytics.nn.modules.block.RepNCSPELAN4    [224, 96, 96, 48, 3]          \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     71360  ultralytics.nn.modules.block.RepNCSPELAN4    [160, 64, 64, 32, 3]          \n",
      " 16                  -1  1     27744  ultralytics.nn.modules.block.AConv           [64, 48]                      \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    150432  ultralytics.nn.modules.block.RepNCSPELAN4    [144, 96, 96, 48, 3]          \n",
      " 19                  -1  1     55424  ultralytics.nn.modules.block.AConv           [96, 64]                      \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    266624  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 128, 128, 64, 3]        \n",
      " 22        [15, 18, 21]  1    567577  ultralytics.nn.modules.head.Detect           [3, [64, 96, 128]]            \n",
      "YOLOv9t summary: 544 layers, 2,005,993 parameters, 2,005,977 gradients, 7.9 GFLOPs\n",
      "\n",
      "Transferred 1303/1339 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 1.80.3 ms, read: 2.80.3 MB/s, size: 52.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\train\\labels.cache... 9 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 3.6Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 1.80.5 ms, read: 2.00.6 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.5Kit/s 0.0s\n",
      "Plotting labels to G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_aug\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 221 weight(decay=0.0), 228 weight(decay=0.0005), 227 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_aug\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50         0G      1.872      4.212     0.9666          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 2.0s/it 4.0s4.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
      "                   all          3         19    0.00181     0.0952    0.00132    0.00071\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50         0G      1.686      3.993     0.9566          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.3s3.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19    0.00184     0.0952     0.0015   0.000536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50         0G      1.046      4.011      0.865          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.4s3.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
      "                   all          3         19    0.00547      0.286    0.00551    0.00132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50         0G      1.079      3.942     0.8786          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.8s/it 3.5s3.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.6s\n",
      "                   all          3         19    0.00756      0.352    0.00652    0.00183\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50         0G      1.412      3.655     0.8769          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.8s/it 3.6s4.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19     0.0107      0.467     0.0131    0.00505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50         0G      1.497      3.478     0.8831          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s3.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.5it/s 0.6s\n",
      "                   all          3         19     0.0154      0.676     0.0247     0.0104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50         0G      1.357      3.262     0.8597          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.3s3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19     0.0201      0.886     0.0416     0.0225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50         0G      1.153      3.115     0.8772          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s3.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19     0.0227          1     0.0551     0.0317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50         0G      0.796       3.27     0.8169          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
      "                   all          3         19      0.022          1     0.0659     0.0443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50         0G     0.8364      2.712     0.8179         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s4.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
      "                   all          3         19     0.0219          1      0.071     0.0459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50         0G     0.8071      2.674     0.8079          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 2.9s3.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19     0.0218          1     0.0725     0.0447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50         0G      1.031      1.938     0.8132          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.7s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19     0.0218          1     0.0725     0.0447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50         0G     0.8128      2.453     0.7981          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s2.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19     0.0216          1     0.0755     0.0459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50         0G      0.621      1.622     0.8033          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.1s4.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.5s\n",
      "                   all          3         19     0.0217          1      0.134     0.0821\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50         0G     0.6789      1.446     0.7897          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19     0.0217          1      0.134     0.0821\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50         0G     0.7819      1.395     0.7908          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.5s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19     0.0218          1       0.35      0.229\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50         0G     0.7312      1.157     0.7855          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s3.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
      "                   all          3         19     0.0219          1       0.39       0.27\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50         0G     0.8069      2.271     0.7891          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.9s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19     0.0219          1       0.39       0.27\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50         0G      0.649      1.187     0.7879         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s3.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
      "                   all          3         19     0.0222          1      0.438       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50         0G      0.661      1.585     0.7714          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 2.9s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19     0.0222          1      0.438       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50         0G     0.8106        1.3     0.7589          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.3s3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.5s\n",
      "                   all          3         19      0.656      0.429      0.727      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50         0G     0.6516      1.501      0.784          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19      0.656      0.429      0.727      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50         0G     0.5976      1.516     0.8261          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.1s3.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.5s\n",
      "                   all          3         19      0.908      0.286       0.81      0.586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50         0G     0.9053      2.377     0.7826          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 2.9s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19      0.908      0.286       0.81      0.586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50         0G     0.6206     0.9883     0.7932          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.1s3.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19      0.845      0.286      0.857      0.604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50         0G     0.6557     0.9838     0.7583          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.845      0.286      0.857      0.604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50         0G      0.668     0.9756     0.7853          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.1s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.5s\n",
      "                   all          3         19      0.845      0.286      0.857      0.604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50         0G     0.7982       2.31     0.7738          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.1s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19      0.854      0.629      0.891      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50         0G     0.6974      1.178     0.7782          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.9s3.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19      0.854      0.629      0.891      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50         0G      0.722      1.242     0.7969          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.3s4.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.873      0.794      0.949      0.686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50         0G     0.6881     0.8722     0.7621          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s3.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.873      0.794      0.949      0.686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50         0G     0.8501      1.004     0.8248          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.9s2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
      "                   all          3         19      0.873      0.794      0.949      0.686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50         0G     0.6544     0.9818     0.8057         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.5s2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19      0.838      0.873       0.96       0.69\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50         0G     0.6919      1.368     0.7986          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.7s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.5s\n",
      "                   all          3         19      0.838      0.873       0.96       0.69\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50         0G     0.7256     0.9504     0.8038          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.6s\n",
      "                   all          3         19      0.838      0.873       0.96       0.69\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50         0G     0.8835      2.095     0.8086          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19      0.886      0.899      0.974      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50         0G     0.6375     0.8482     0.8196          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19      0.886      0.899      0.974      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50         0G     0.9114      1.913     0.7904          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.886      0.899      0.974      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50         0G     0.6461     0.9444     0.7973          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.895      0.944      0.989       0.83\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50         0G     0.5204     0.9321     0.8098         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.895      0.944      0.989       0.83\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50         0G     0.7099     0.9546      0.789          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
      "                   all          3         19      0.895      0.944      0.989       0.83\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50         0G     0.6551     0.9435     0.7783          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.1s3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
      "                   all          3         19      0.897      0.962      0.995      0.865\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50         0G     0.5296     0.8544     0.7806          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.897      0.962      0.995      0.865\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50         0G     0.6174      1.029     0.7795          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s3.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.897      0.962      0.995      0.865\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50         0G     0.5707     0.7546     0.7777          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s3.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
      "                   all          3         19      0.897      0.962      0.995      0.865\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50         0G     0.5773     0.7828     0.8097          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s3.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19      0.903      0.966      0.995      0.884\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50         0G     0.6152     0.7538     0.7747          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19      0.903      0.966      0.995      0.884\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50         0G     0.5796      1.214     0.7662          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.9s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.903      0.966      0.995      0.884\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50         0G     0.6867      2.058     0.7889          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s2.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.6s\n",
      "                   all          3         19      0.903      0.966      0.995      0.884\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50         0G     0.6755     0.7849       0.79          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.1s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19      0.905      0.948      0.995      0.877\n",
      "\n",
      "50 epochs completed in 0.068 hours.\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_aug\\weights\\last.pt, 4.5MB\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_aug\\weights\\best.pt, 4.5MB\n",
      "\n",
      "Validating G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_aug\\weights\\best.pt...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "YOLOv9t summary (fused): 197 layers, 1,971,369 parameters, 0 gradients, 7.6 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.5s\n",
      "                   all          3         19      0.903      0.966      0.995      0.884\n",
      "            light_blue          1          5      0.853          1      0.995      0.975\n",
      "             dark_blue          1          7      0.856          1      0.995      0.814\n",
      "                others          1          7          1      0.898      0.995      0.862\n",
      "Speed: 0.4ms preprocess, 73.8ms inference, 0.0ms loss, 2.1ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_aug\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg1</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg2</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–„â–ƒâ–‚</td></tr><tr><td>metrics/mAP50(B)</td><td>â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–„â–„â–„â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/mAP50-95(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/precision(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/recall(B)</td><td>â–â–â–‚â–ƒâ–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–„â–‚â–‚â–‚â–‚â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>model/GFLOPs</td><td>â–</td></tr><tr><td>model/parameters</td><td>â–</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>â–</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.995</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.87711</td></tr><tr><td>metrics/precision(B)</td><td>0.90479</td></tr><tr><td>metrics/recall(B)</td><td>0.94774</td></tr><tr><td>model/GFLOPs</td><td>7.851</td></tr><tr><td>model/parameters</td><td>2005993</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>142.634</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolov9t_320_aug</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/48mcxl4v' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/48mcxl4v</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 20 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_093319-48mcxl4v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Running Validation...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "YOLOv9t summary (fused): 197 layers, 1,971,369 parameters, 0 gradients, 7.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 2.61.7 ms, read: 2.20.6 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.0Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19      0.903      0.966      0.995      0.884\n",
      "            light_blue          1          5      0.853          1      0.995      0.975\n",
      "             dark_blue          1          7      0.856          1      0.995      0.814\n",
      "                others          1          7          1      0.898      0.995      0.862\n",
      "Speed: 0.3ms preprocess, 96.4ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\runs\\detect\\val49\u001b[0m\n",
      "ğŸ“¦ Exporting to ONNX...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_aug\\weights\\best.pt' with input shape (1, 3, 320, 320) BCHW and output shape(s) (1, 7, 2100) (4.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.74...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  4.6s, saved as 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_aug\\weights\\best.onnx' (7.8 MB)\n",
      "\n",
      "Export complete (5.0s)\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_aug\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_aug\\weights\\best.onnx imgsz=320  \n",
      "Validate:        yolo val task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_aug\\weights\\best.onnx imgsz=320 data=../datasets/bottle_cap/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "â±ï¸ Running Benchmark on: Bottle-Cap-Detection\\yolov9t_320_aug\\weights\\best.onnx\n",
      "âœ… Speed Result: 42.74 ms (23.4 FPS)\n",
      "ğŸ”„ Re-connecting ke Run ID: 48mcxl4v...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_093811-48mcxl4v</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/48mcxl4v' target=\"_blank\">yolov9t_320_aug</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/48mcxl4v' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/48mcxl4v</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data benchmark berhasil dikirim ke WandB!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>â–</td></tr><tr><td>inference/onnx_fps</td><td>â–</td></tr><tr><td>model/size_mb</td><td>â–</td></tr><tr><td>val/mAP50</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>42.73753</td></tr><tr><td>inference/onnx_fps</td><td>23.39864</td></tr><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.995</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.87711</td></tr><tr><td>metrics/precision(B)</td><td>0.90479</td></tr><tr><td>metrics/recall(B)</td><td>0.94774</td></tr><tr><td>model/GFLOPs</td><td>7.851</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolov9t_320_aug</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/48mcxl4v' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/48mcxl4v</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_093811-48mcxl4v\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”’ Sesi WandB ditutup.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42.73752689361572"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jalankan Eksperimen 1: Ukuran 320, Augmentasi Aman\n",
    "run_experiment(\n",
    "    model_name='yolov9t.pt', \n",
    "    exp_name='yolov9t_320_aug', \n",
    "    img_size=320, \n",
    "    use_safe_aug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4238b3ed",
   "metadata": {},
   "source": [
    "### FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ebe6b0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ START FP16 EXPERIMENT: yolov9t_320_fp16 | Size: 320 | Safe Aug: True\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_093815-sloxdpqq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/sloxdpqq' target=\"_blank\">yolov9t_320_fp16</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/sloxdpqq' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/sloxdpqq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›¡ï¸ Mengaktifkan SAFE MODE (Augmentasi Warna OFF)...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../datasets/bottle_cap/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov9t.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=yolov9t_320_fp16, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=Bottle-Cap-Detection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_fp16, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.1, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7872  ultralytics.nn.modules.block.ELAN1           [32, 32, 32, 16]              \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.block.AConv           [32, 64]                      \n",
      "  4                  -1  1     65216  ultralytics.nn.modules.block.RepNCSPELAN4    [64, 64, 64, 32, 3]           \n",
      "  5                  -1  1     55488  ultralytics.nn.modules.block.AConv           [64, 96]                      \n",
      "  6                  -1  1    145824  ultralytics.nn.modules.block.RepNCSPELAN4    [96, 96, 96, 48, 3]           \n",
      "  7                  -1  1    110848  ultralytics.nn.modules.block.AConv           [96, 128]                     \n",
      "  8                  -1  1    258432  ultralytics.nn.modules.block.RepNCSPELAN4    [128, 128, 128, 64, 3]        \n",
      "  9                  -1  1     41344  ultralytics.nn.modules.block.SPPELAN         [128, 128, 64]                \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    158112  ultralytics.nn.modules.block.RepNCSPELAN4    [224, 96, 96, 48, 3]          \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     71360  ultralytics.nn.modules.block.RepNCSPELAN4    [160, 64, 64, 32, 3]          \n",
      " 16                  -1  1     27744  ultralytics.nn.modules.block.AConv           [64, 48]                      \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    150432  ultralytics.nn.modules.block.RepNCSPELAN4    [144, 96, 96, 48, 3]          \n",
      " 19                  -1  1     55424  ultralytics.nn.modules.block.AConv           [96, 64]                      \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    266624  ultralytics.nn.modules.block.RepNCSPELAN4    [192, 128, 128, 64, 3]        \n",
      " 22        [15, 18, 21]  1    567577  ultralytics.nn.modules.head.Detect           [3, [64, 96, 128]]            \n",
      "YOLOv9t summary: 544 layers, 2,005,993 parameters, 2,005,977 gradients, 7.9 GFLOPs\n",
      "\n",
      "Transferred 1303/1339 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 1.80.5 ms, read: 2.40.2 MB/s, size: 52.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\train\\labels.cache... 9 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 8.3Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 1.80.8 ms, read: 2.00.6 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.5Kit/s 0.0s\n",
      "Plotting labels to G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_fp16\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 221 weight(decay=0.0), 228 weight(decay=0.0005), 227 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_fp16\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50         0G      1.872      4.212     0.9666          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.8s/it 3.6s3.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.6it/s 0.6s\n",
      "                   all          3         19    0.00181     0.0952    0.00132    0.00071\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50         0G      1.686      3.993     0.9566          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.9s/it 3.8s3.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.6it/s 0.6s\n",
      "                   all          3         19    0.00184     0.0952     0.0015   0.000536\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50         0G      1.046      4.011      0.865          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.4s3.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19    0.00547      0.286    0.00551    0.00132\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50         0G      1.079      3.942     0.8786          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.8s/it 3.6s3.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.6it/s 0.6s\n",
      "                   all          3         19    0.00756      0.352    0.00652    0.00183\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50         0G      1.412      3.655     0.8769          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s3.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.6it/s 0.6s\n",
      "                   all          3         19     0.0107      0.467     0.0131    0.00505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50         0G      1.497      3.478     0.8831          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.8s/it 3.5s4.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.4it/s 0.7s\n",
      "                   all          3         19     0.0154      0.676     0.0247     0.0104\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50         0G      1.357      3.262     0.8597          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s3.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19     0.0201      0.886     0.0416     0.0225\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50         0G      1.153      3.115     0.8772          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.4s3.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.6s\n",
      "                   all          3         19     0.0227          1     0.0551     0.0317\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50         0G      0.796       3.27     0.8169          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.1s3.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.6it/s 0.6s\n",
      "                   all          3         19      0.022          1     0.0659     0.0443\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50         0G     0.8364      2.712     0.8179         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s3.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19     0.0219          1      0.071     0.0459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50         0G     0.8071      2.674     0.8079          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.1s3.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.6it/s 0.6s\n",
      "                   all          3         19     0.0218          1     0.0725     0.0447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50         0G      1.031      1.938     0.8132          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s3.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19     0.0218          1     0.0725     0.0447\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50         0G     0.8128      2.453     0.7981          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19     0.0216          1     0.0755     0.0459\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50         0G      0.621      1.622     0.8033          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.3s4.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19     0.0217          1      0.134     0.0821\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50         0G     0.6789      1.446     0.7897          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 2.9s2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19     0.0217          1      0.134     0.0821\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50         0G     0.7819      1.395     0.7908          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s2.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19     0.0218          1       0.35      0.229\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50         0G     0.7312      1.157     0.7855          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s3.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
      "                   all          3         19     0.0219          1       0.39       0.27\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50         0G     0.8069      2.271     0.7891          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.9s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.6s\n",
      "                   all          3         19     0.0219          1       0.39       0.27\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50         0G      0.649      1.187     0.7879         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.1s3.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.6it/s 0.6s\n",
      "                   all          3         19     0.0222          1      0.438       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50         0G      0.661      1.585     0.7714          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 2.9s2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19     0.0222          1      0.438       0.31\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50         0G     0.8106        1.3     0.7589          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.4s4.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.6s\n",
      "                   all          3         19      0.656      0.429      0.727      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50         0G     0.6516      1.501      0.784          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 2.9s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.656      0.429      0.727      0.548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50         0G     0.5976      1.516     0.8261          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.1s3.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.908      0.286       0.81      0.586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50         0G     0.9053      2.377     0.7826          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.9s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19      0.908      0.286       0.81      0.586\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50         0G     0.6206     0.9883     0.7932          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.3s3.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.845      0.286      0.857      0.604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50         0G     0.6557     0.9838     0.7583          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.845      0.286      0.857      0.604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50         0G      0.668     0.9756     0.7853          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.9s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.845      0.286      0.857      0.604\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50         0G     0.7982       2.31     0.7738          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.1s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.854      0.629      0.891      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50         0G     0.6974      1.178     0.7782          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.5s\n",
      "                   all          3         19      0.854      0.629      0.891      0.629\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50         0G      0.722      1.242     0.7969          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.4s4.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.873      0.794      0.949      0.686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50         0G     0.6881     0.8722     0.7621          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 2.9s3.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19      0.873      0.794      0.949      0.686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50         0G     0.8501      1.004     0.8248          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s3.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.873      0.794      0.949      0.686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50         0G     0.6544     0.9818     0.8057         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.5s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.5s\n",
      "                   all          3         19      0.838      0.873       0.96       0.69\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50         0G     0.6919      1.368     0.7986          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.1s3.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19      0.838      0.873       0.96       0.69\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50         0G     0.7256     0.9504     0.8038          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.7it/s 0.6s\n",
      "                   all          3         19      0.838      0.873       0.96       0.69\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50         0G     0.8835      2.095     0.8086          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.1s2.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.886      0.899      0.974      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50         0G     0.6375     0.8482     0.8196          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s3.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.886      0.899      0.974      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50         0G     0.9114      1.913     0.7904          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 2.9s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19      0.886      0.899      0.974      0.799\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50         0G     0.6461     0.9444     0.7973          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.2s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19      0.895      0.944      0.989       0.83\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50         0G     0.5204     0.9321     0.8098         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4s/it 2.8s2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.895      0.944      0.989       0.83\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50         0G     0.7099     0.9546      0.789          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s3.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19      0.895      0.944      0.989       0.83\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50         0G     0.6551     0.9435     0.7783          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6s/it 3.3s4.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.897      0.962      0.995      0.865\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50         0G     0.5296     0.8544     0.7806          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19      0.897      0.962      0.995      0.865\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50         0G     0.6174      1.029     0.7795          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s2.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19      0.897      0.962      0.995      0.865\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50         0G     0.5707     0.7546     0.7777          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.9it/s 0.5s\n",
      "                   all          3         19      0.897      0.962      0.995      0.865\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50         0G     0.5773     0.7828     0.8097          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7s/it 3.4s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 1.8it/s 0.5s\n",
      "                   all          3         19      0.903      0.966      0.995      0.884\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50         0G     0.6152     0.7538     0.7747          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19      0.903      0.966      0.995      0.884\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50         0G     0.5796      1.214     0.7662          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19      0.903      0.966      0.995      0.884\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50         0G     0.6867      2.058     0.7889          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.0s3.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19      0.903      0.966      0.995      0.884\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50         0G     0.6755     0.7849       0.79          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5s/it 3.1s2.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19      0.905      0.948      0.995      0.877\n",
      "\n",
      "50 epochs completed in 0.068 hours.\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_fp16\\weights\\last.pt, 4.5MB\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_fp16\\weights\\best.pt, 4.5MB\n",
      "\n",
      "Validating G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_fp16\\weights\\best.pt...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "YOLOv9t summary (fused): 197 layers, 1,971,369 parameters, 0 gradients, 7.6 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19      0.903      0.966      0.995      0.884\n",
      "            light_blue          1          5      0.853          1      0.995      0.975\n",
      "             dark_blue          1          7      0.856          1      0.995      0.814\n",
      "                others          1          7          1      0.898      0.995      0.862\n",
      "Speed: 0.3ms preprocess, 85.1ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_fp16\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg1</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg2</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>metrics/mAP50(B)</td><td>â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–„â–„â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/mAP50-95(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–ƒâ–ƒâ–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/precision(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/recall(B)</td><td>â–â–â–‚â–ƒâ–„â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–„â–„â–‚â–‚â–‚â–‚â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>model/GFLOPs</td><td>â–</td></tr><tr><td>model/parameters</td><td>â–</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>â–</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.995</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.87711</td></tr><tr><td>metrics/precision(B)</td><td>0.90479</td></tr><tr><td>metrics/recall(B)</td><td>0.94774</td></tr><tr><td>model/GFLOPs</td><td>7.851</td></tr><tr><td>model/parameters</td><td>2005993</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>144.975</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolov9t_320_fp16</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/sloxdpqq' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/sloxdpqq</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 20 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_093815-sloxdpqq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Running Validation...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "YOLOv9t summary (fused): 197 layers, 1,971,369 parameters, 0 gradients, 7.6 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 1.60.6 ms, read: 2.20.8 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.0Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19      0.903      0.966      0.995      0.884\n",
      "            light_blue          1          5      0.853          1      0.995      0.975\n",
      "             dark_blue          1          7      0.856          1      0.995      0.814\n",
      "                others          1          7          1      0.898      0.995      0.862\n",
      "Speed: 0.2ms preprocess, 95.3ms inference, 0.0ms loss, 2.4ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\runs\\detect\\val50\u001b[0m\n",
      "\n",
      "ğŸ“¦ Exporting to OpenVINO FP16...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_fp16\\weights\\best.pt' with input shape (1, 3, 320, 320) BCHW and output shape(s) (1, 7, 2100) (4.4 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2024.6.0-17404-4c0f47d2335-releases/2024/6...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success  16.2s, saved as 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_fp16\\weights\\best_openvino_model\\' (4.6 MB)\n",
      "\n",
      "Export complete (16.6s)\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_fp16\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_fp16\\weights\\best_openvino_model imgsz=320 half \n",
      "Validate:        yolo val task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolov9t_320_fp16\\weights\\best_openvino_model imgsz=320 data=../datasets/bottle_cap/data.yaml half \n",
      "Visualize:       https://netron.app\n",
      "â±ï¸ Running Benchmark on: Bottle-Cap-Detection\\yolov9t_320_fp16\\weights\\best_openvino_model\n",
      "Loading Bottle-Cap-Detection\\yolov9t_320_fp16\\weights\\best_openvino_model for OpenVINO inference...\n",
      "Using OpenVINO LATENCY mode for batch=1 inference on (CPU)...\n",
      "âœ… Speed Result (FP16): 45.74 ms (21.9 FPS)\n",
      "ğŸ”„ Re-connecting ke Run ID: sloxdpqq...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_094321-sloxdpqq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/sloxdpqq' target=\"_blank\">yolov9t_320_fp16</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/sloxdpqq' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/sloxdpqq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data FP16 berhasil dikirim ke WandB!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>â–</td></tr><tr><td>inference/openvino_fp16_fps</td><td>â–</td></tr><tr><td>model/size_mb</td><td>â–</td></tr><tr><td>val/mAP50</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>45.73826</td></tr><tr><td>inference/openvino_fp16_fps</td><td>21.86353</td></tr><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.995</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.87711</td></tr><tr><td>metrics/precision(B)</td><td>0.90479</td></tr><tr><td>metrics/recall(B)</td><td>0.94774</td></tr><tr><td>model/GFLOPs</td><td>7.851</td></tr><tr><td>+17</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolov9t_320_fp16</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/sloxdpqq' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/sloxdpqq</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_094321-sloxdpqq\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”’ WandB Session Closed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "45.73826313018799"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Jalankan FP16 dengan Size 320\n",
    "run_experiment_fp16(\n",
    "    model_name='yolov9t.pt',       # atau 'yolo11n.pt'\n",
    "    exp_name='yolov9t_320_fp16', \n",
    "    img_size=320, \n",
    "    use_safe_aug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daca69af",
   "metadata": {},
   "source": [
    "## YOLOv5nu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6fda474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ START EXPERIMENT: yolo5nu_320 | Size: 320 | Safe Aug: False\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_094325-x9xqlskj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/x9xqlskj' target=\"_blank\">yolo5nu_320</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/x9xqlskj' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/x9xqlskj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../datasets/bottle_cap/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov5nu.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo5nu_320, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=Bottle-Cap-Detection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo5nu_320, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1760  ultralytics.nn.modules.conv.Conv             [3, 16, 6, 2, 2]              \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      4800  ultralytics.nn.modules.block.C3              [32, 32, 1]                   \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     29184  ultralytics.nn.modules.block.C3              [64, 64, 2]                   \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  3    156928  ultralytics.nn.modules.block.C3              [128, 128, 3]                 \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1]                 \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1     33024  ultralytics.nn.modules.conv.Conv             [256, 128, 1, 1]              \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1     90880  ultralytics.nn.modules.block.C3              [256, 128, 1, False]          \n",
      " 14                  -1  1      8320  ultralytics.nn.modules.conv.Conv             [128, 64, 1, 1]               \n",
      " 15                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 16             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 17                  -1  1     22912  ultralytics.nn.modules.block.C3              [128, 64, 1, False]           \n",
      " 18                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 19            [-1, 14]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 20                  -1  1     74496  ultralytics.nn.modules.block.C3              [128, 128, 1, False]          \n",
      " 21                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 22            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 23                  -1  1    296448  ultralytics.nn.modules.block.C3              [256, 256, 1, False]          \n",
      " 24        [17, 20, 23]  1    751897  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLOv5n summary: 153 layers, 2,509,049 parameters, 2,509,033 gradients, 7.2 GFLOPs\n",
      "\n",
      "Transferred 391/427 items from pretrained weights\n",
      "Freezing layer 'model.24.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 2.00.2 ms, read: 2.50.4 MB/s, size: 52.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\train\\labels.cache... 9 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.5Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 2.10.9 ms, read: 2.00.5 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.0Kit/s 0.0s\n",
      "Plotting labels to G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo5nu_320\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 69 weight(decay=0.0), 76 weight(decay=0.0005), 75 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo5nu_320\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50         0G      1.907      4.364      1.006          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1s/it 2.3s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19     0.0106        0.6     0.0115    0.00813\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50         0G       1.63      4.191     0.9566          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.1s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19     0.0101        0.6     0.0121    0.00879\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50         0G      1.752      4.199     0.9078         18        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
      "                   all          3         19    0.00977        0.6     0.0147    0.00937\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50         0G     0.8867      3.951     0.8556          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8it/s 0.3s\n",
      "                   all          3         19     0.0135      0.629     0.0192    0.00971\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50         0G      1.024      4.023     0.8509          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.6s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
      "                   all          3         19     0.0185      0.724     0.0276     0.0145\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50         0G      1.039      3.792     0.8309         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19     0.0234      0.905     0.0381     0.0212\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50         0G      1.307      3.808     0.8329         24        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
      "                   all          3         19     0.0256      0.952     0.0545     0.0334\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50         0G       1.17       3.35     0.8583          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19     0.0259      0.952     0.0628     0.0465\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50         0G      1.243      3.453     0.8296         24        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19     0.0263          1     0.0644     0.0483\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50         0G      1.028      3.308     0.8387         17        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 2.0s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19      0.025          1     0.0694     0.0525\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50         0G     0.8752      2.451     0.8539          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19     0.0238          1     0.0698     0.0539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50         0G     0.9626      1.722     0.7765          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19     0.0238          1     0.0698     0.0539\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50         0G       1.07      2.062     0.7963          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.7it/s 0.3s\n",
      "                   all          3         19     0.0234          1     0.0689     0.0537\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50         0G     0.8675      2.321     0.8143         16        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.1s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.3s\n",
      "                   all          3         19     0.0233          1     0.0895     0.0686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50         0G      1.259      2.475      0.824         14        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.5s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6it/s 0.3s\n",
      "                   all          3         19     0.0233          1     0.0895     0.0686\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50         0G      1.265      3.032     0.8215         21        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.2it/s 0.2s\n",
      "                   all          3         19      0.023          1      0.143      0.101\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50         0G       1.11      1.926     0.8448         21        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.0s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19      0.023          1      0.339      0.212\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50         0G     0.7659      1.873     0.7434         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19      0.023          1      0.339      0.212\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50         0G      1.003      1.696     0.7997         22        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.3s\n",
      "                   all          3         19     0.0229          1      0.492      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50         0G     0.6516      1.022     0.7941          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
      "                   all          3         19     0.0229          1      0.492      0.313\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50         0G      1.124       4.19     0.8474          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1s/it 2.1s2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
      "                   all          3         19     0.0228          1      0.551      0.407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50         0G     0.9298      2.393     0.7994          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.7it/s 0.3s\n",
      "                   all          3         19     0.0228          1      0.551      0.407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50         0G      1.096       1.91      0.823          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
      "                   all          3         19     0.0226          1      0.605      0.456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50         0G     0.6798      1.006     0.8418          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6it/s 0.3s\n",
      "                   all          3         19     0.0226          1      0.605      0.456\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50         0G      1.002      2.555     0.8304          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.7it/s 0.3s\n",
      "                   all          3         19     0.0223          1      0.535      0.399\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50         0G      1.071      2.388     0.7813         11        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.6s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.1it/s 0.3s\n",
      "                   all          3         19     0.0223          1      0.535      0.399\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50         0G      1.328      1.663     0.8352          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.5it/s 0.3s\n",
      "                   all          3         19     0.0223          1      0.535      0.399\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50         0G      1.112      1.853     0.7946         19        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19      0.431      0.479      0.535      0.392\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50         0G     0.8739      1.502     0.8105         22        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19      0.431      0.479      0.535      0.392\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50         0G     0.9787      1.875      0.828         21        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s2.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.5it/s 0.3s\n",
      "                   all          3         19      0.775      0.227      0.539      0.432\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50         0G       0.89      1.596     0.8552         15        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.5it/s 0.3s\n",
      "                   all          3         19      0.775      0.227      0.539      0.432\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50         0G     0.9364      1.506     0.8082         15        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.6s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19      0.775      0.227      0.539      0.432\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50         0G      1.013      2.295     0.8057          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19      0.447      0.267      0.586      0.478\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50         0G      0.687      1.206     0.8271          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
      "                   all          3         19      0.447      0.267      0.586      0.478\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50         0G     0.9579      2.589      0.854          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19      0.447      0.267      0.586      0.478\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50         0G      0.627       1.28     0.7924         15        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19      0.441      0.333      0.586      0.475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50         0G     0.5802      1.011     0.8141          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
      "                   all          3         19      0.441      0.333      0.586      0.475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50         0G     0.7059     0.9786      0.764          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6it/s 0.3s\n",
      "                   all          3         19      0.441      0.333      0.586      0.475\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50         0G      1.135      1.363     0.8181         16        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6it/s 0.3s\n",
      "                   all          3         19      0.533      0.624      0.581       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50         0G     0.9023      1.568     0.8241         25        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.6s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.5it/s 0.3s\n",
      "                   all          3         19      0.533      0.624      0.581       0.46\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50         0G     0.6283      1.319     0.8458          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.6s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8it/s 0.3s\n",
      "                   all          3         19      0.533      0.624      0.581       0.46\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50         0G     0.6601     0.9583     0.6892          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6it/s 0.3s\n",
      "                   all          3         19      0.536      0.693      0.553      0.439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50         0G     0.6244     0.9794     0.8155          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.6s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19      0.536      0.693      0.553      0.439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50         0G     0.9706      2.164     0.7932          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.4s1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19      0.536      0.693      0.553      0.439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50         0G     0.7599     0.8838     0.7782          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
      "                   all          3         19      0.536      0.693      0.553      0.439\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50         0G     0.5452     0.9416     0.8251          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6it/s 0.3s\n",
      "                   all          3         19      0.542      0.767      0.645      0.519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50         0G     0.5787     0.9019     0.7858          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19      0.542      0.767      0.645      0.519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50         0G     0.6219      1.738     0.7717          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19      0.542      0.767      0.645      0.519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50         0G     0.7004      2.212     0.7957          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19      0.542      0.767      0.645      0.519\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50         0G     0.6124     0.9486      0.787          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6it/s 0.3s\n",
      "                   all          3         19      0.541      0.795      0.665      0.539\n",
      "\n",
      "50 epochs completed in 0.037 hours.\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo5nu_320\\weights\\last.pt, 4.8MB\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo5nu_320\\weights\\best.pt, 4.8MB\n",
      "\n",
      "Validating G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo5nu_320\\weights\\best.pt...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
      "                   all          3         19       0.54      0.795      0.665      0.539\n",
      "            light_blue          1          5      0.257          1      0.442      0.358\n",
      "             dark_blue          1          7      0.364          1      0.558       0.43\n",
      "                others          1          7          1      0.386      0.995      0.828\n",
      "Speed: 0.4ms preprocess, 46.8ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo5nu_320\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg1</td><td>â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg2</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>metrics/mAP50(B)</td><td>â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/mAP50-95(B)</td><td>â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–„â–…â–†â–†â–‡â–‡â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/precision(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–…â–…â–ˆâ–ˆâ–…â–…â–…â–…â–†â–†â–†â–†â–†â–†â–†â–†â–†â–†</td></tr><tr><td>metrics/recall(B)</td><td>â–„â–„â–„â–…â–…â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ƒâ–ƒâ–â–â–â–â–â–‚â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†</td></tr><tr><td>model/GFLOPs</td><td>â–</td></tr><tr><td>model/parameters</td><td>â–</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>â–</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.66505</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.53871</td></tr><tr><td>metrics/precision(B)</td><td>0.54051</td></tr><tr><td>metrics/recall(B)</td><td>0.79513</td></tr><tr><td>model/GFLOPs</td><td>7.179</td></tr><tr><td>model/parameters</td><td>2509049</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>56.5</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo5nu_320</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/x9xqlskj' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/x9xqlskj</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 20 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_094325-x9xqlskj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Running Validation...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "YOLOv5n summary (fused): 84 layers, 2,503,529 parameters, 0 gradients, 7.1 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 1.80.8 ms, read: 1.90.8 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.9Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.7it/s 0.2s\n",
      "                   all          3         19       0.54      0.795      0.665      0.539\n",
      "            light_blue          1          5      0.257          1      0.442      0.358\n",
      "             dark_blue          1          7      0.364          1      0.558       0.43\n",
      "                others          1          7          1      0.386      0.995      0.828\n",
      "Speed: 1.4ms preprocess, 47.1ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\runs\\detect\\val51\u001b[0m\n",
      "ğŸ“¦ Exporting to ONNX...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo5nu_320\\weights\\best.pt' with input shape (1, 3, 320, 320) BCHW and output shape(s) (1, 7, 2100) (5.0 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.74...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  1.9s, saved as 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo5nu_320\\weights\\best.onnx' (9.7 MB)\n",
      "\n",
      "Export complete (2.2s)\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo5nu_320\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo5nu_320\\weights\\best.onnx imgsz=320  \n",
      "Validate:        yolo val task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo5nu_320\\weights\\best.onnx imgsz=320 data=../datasets/bottle_cap/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "â±ï¸ Running Benchmark on: Bottle-Cap-Detection\\yolo5nu_320\\weights\\best.onnx\n",
      "âœ… Speed Result: 34.75 ms (28.8 FPS)\n",
      "ğŸ”„ Re-connecting ke Run ID: x9xqlskj...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_094618-x9xqlskj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/x9xqlskj' target=\"_blank\">yolo5nu_320</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/x9xqlskj' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/x9xqlskj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data benchmark berhasil dikirim ke WandB!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>â–</td></tr><tr><td>inference/onnx_fps</td><td>â–</td></tr><tr><td>model/size_mb</td><td>â–</td></tr><tr><td>val/mAP50</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>34.7533</td></tr><tr><td>inference/onnx_fps</td><td>28.77424</td></tr><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.66505</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.53871</td></tr><tr><td>metrics/precision(B)</td><td>0.54051</td></tr><tr><td>metrics/recall(B)</td><td>0.79513</td></tr><tr><td>model/GFLOPs</td><td>7.179</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo5nu_320</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/x9xqlskj' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/x9xqlskj</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_094618-x9xqlskj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”’ Sesi WandB ditutup.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "34.75330352783203"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jalankan Eksperimen 1: Ukuran 320, Augmentasi Aman\n",
    "run_experiment(\n",
    "    model_name='yolov5nu.pt', \n",
    "    exp_name='yolo5nu_320', \n",
    "    img_size=320, \n",
    "    use_safe_aug=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efafbe5d",
   "metadata": {},
   "source": [
    "## YOLO11n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c0ea2506",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ START EXPERIMENT: yolo11n_320 | Size: 320 | Safe Aug: False\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_094622-z3aqs5fz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/z3aqs5fz' target=\"_blank\">yolo11n_320</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/z3aqs5fz' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/z3aqs5fz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../datasets/bottle_cap/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=yolo11n_320, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=Bottle-Cap-Detection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431257  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,425 parameters, 2,590,409 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 1.80.4 ms, read: 2.50.5 MB/s, size: 52.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\train\\labels.cache... 9 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.5Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 1.70.6 ms, read: 2.30.5 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.9Kit/s 0.0s\n",
      "Plotting labels to G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50         0G       1.73      3.861     0.9595          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3s/it 2.6s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.3s\n",
      "                   all          3         19    0.00708      0.429     0.0133    0.00736\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50         0G      1.468       3.88     0.9351          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2s/it 2.4s2.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
      "                   all          3         19     0.0082      0.476     0.0151     0.0098\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50         0G      1.489      3.821      0.873         18        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1s/it 2.2s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19    0.00918      0.524     0.0176     0.0106\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50         0G     0.8937      3.705     0.8428          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1s/it 2.1s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19     0.0148      0.714     0.0265     0.0118\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50         0G      1.033      3.594     0.8482          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 1.9s2.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
      "                   all          3         19     0.0139      0.714     0.0281     0.0131\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50         0G      1.072      3.644     0.8218         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6it/s 0.3s\n",
      "                   all          3         19     0.0134      0.714     0.0324     0.0171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50         0G      1.159      3.554     0.8214         24        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 2.0s2.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19      0.013      0.714     0.0314     0.0206\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50         0G       1.05      3.446     0.8329          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.1s2.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19     0.0153      0.762     0.0466     0.0307\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50         0G      1.237      3.544     0.8279         24        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.0s2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
      "                   all          3         19      0.018       0.81     0.0993     0.0508\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50         0G     0.9975      3.275     0.8313         17        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.1s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
      "                   all          3         19     0.0251      0.952      0.105     0.0548\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50         0G      0.798      3.082     0.8433          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 2.0s2.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "                   all          3         19     0.0245      0.952      0.128     0.0601\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50         0G     0.9393      2.752     0.7852          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s2.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
      "                   all          3         19     0.0245      0.952      0.128     0.0601\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50         0G      1.074      2.903     0.8057          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 1.9s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19     0.0245      0.952      0.168     0.0637\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50         0G     0.8625      3.047     0.7962         16        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 1.9s2.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.5it/s 0.3s\n",
      "                   all          3         19     0.0268          1      0.108       0.06\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50         0G     0.8919      3.017     0.8046         14        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.0s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.3s\n",
      "                   all          3         19     0.0268          1      0.108       0.06\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50         0G      1.003      3.114     0.8001         21        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 2.0s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19     0.0262          1      0.107     0.0615\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50         0G      1.098      2.857     0.8347         21        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 1.9s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19     0.0254          1      0.106     0.0551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50         0G     0.7958       2.64       0.76         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
      "                   all          3         19     0.0254          1      0.106     0.0551\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50         0G     0.9385      2.668     0.7815         22        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s2.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
      "                   all          3         19      0.025          1      0.104     0.0349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50         0G      0.766      2.074     0.8185          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19      0.025          1      0.104     0.0349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50         0G     0.8746      2.795     0.8353          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1s/it 2.1s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.7it/s 0.3s\n",
      "                   all          3         19     0.0236          1     0.0346     0.0253\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50         0G      0.872      2.404     0.7958          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19     0.0236          1     0.0346     0.0253\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50         0G     0.8867      2.115     0.7904          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "                   all          3         19     0.0232          1      0.129      0.108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50         0G     0.6412       1.74     0.8359          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.3s\n",
      "                   all          3         19     0.0232          1      0.129      0.108\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50         0G     0.8643      2.347     0.8355          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19     0.0229          1      0.237       0.18\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50         0G     0.8918      2.483     0.7793         11        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
      "                   all          3         19     0.0229          1      0.237       0.18\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50         0G      1.318      2.065     0.8359          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
      "                   all          3         19     0.0229          1      0.237       0.18\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50         0G      1.021      2.235     0.7963         19        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.1s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.1it/s 0.3s\n",
      "                   all          3         19     0.0227          1      0.311      0.233\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50         0G     0.9259      2.075     0.8102         22        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19     0.0227          1      0.311      0.233\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50         0G     0.9404      2.404     0.8046         21        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 2.0s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19     0.0228          1      0.467      0.349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50         0G     0.7771      1.977     0.8331         15        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 1.9s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
      "                   all          3         19     0.0228          1      0.467      0.349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50         0G     0.8539       1.89     0.8052         15        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19     0.0228          1      0.467      0.349\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50         0G     0.8805        2.3     0.7865          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.0s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.4s\n",
      "                   all          3         19     0.0232          1      0.493      0.367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50         0G     0.7606      1.771     0.8326          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19     0.0232          1      0.493      0.367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50         0G     0.9524       2.31      0.831          4        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 2.0s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19     0.0232          1      0.493      0.367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50         0G     0.7111       1.69     0.7875         15        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 1.9s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
      "                   all          3         19     0.0232          1      0.548      0.429\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50         0G     0.7112      1.405     0.8244          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19     0.0232          1      0.548      0.429\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50         0G     0.6508      1.322     0.7388          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19     0.0232          1      0.548      0.429\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50         0G      1.172      1.689     0.8156         16        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 2.0s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19     0.0229          1      0.592      0.481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50         0G     0.8924      1.828     0.8188         25        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19     0.0229          1      0.592      0.481\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50         0G      0.823      1.372     0.8523          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19     0.0229          1      0.592      0.481\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50         0G     0.7217      1.263     0.7205          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.1s3.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19      0.794      0.333      0.778      0.634\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50         0G     0.6582      1.302      0.815          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 1.9s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
      "                   all          3         19      0.794      0.333      0.778      0.634\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50         0G     0.9124      1.692     0.7977          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.6s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19      0.794      0.333      0.778      0.634\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50         0G     0.7334       1.13     0.7933          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19      0.794      0.333      0.778      0.634\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50         0G     0.6247       1.21     0.8348          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 1.9s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.5it/s 0.3s\n",
      "                   all          3         19      0.796      0.333      0.843       0.71\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50         0G     0.5762      1.113      0.781          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19      0.796      0.333      0.843       0.71\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50         0G     0.5691      1.814     0.7672          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19      0.796      0.333      0.843       0.71\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50         0G     0.7433      2.116     0.7781          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.3s\n",
      "                   all          3         19      0.796      0.333      0.843       0.71\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50         0G     0.7474      1.233     0.8004          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
      "                   all          3         19      0.788      0.434      0.866      0.737\n",
      "\n",
      "50 epochs completed in 0.041 hours.\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320\\weights\\last.pt, 5.4MB\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320\\weights\\best.pt, 5.4MB\n",
      "\n",
      "Validating G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320\\weights\\best.pt...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "                   all          3         19      0.788      0.433      0.866      0.737\n",
      "            light_blue          1          5      0.364          1      0.906      0.781\n",
      "             dark_blue          1          7          1          0      0.698       0.59\n",
      "                others          1          7          1      0.299      0.995       0.84\n",
      "Speed: 0.3ms preprocess, 69.0ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>â–â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg1</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg2</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>metrics/mAP50(B)</td><td>â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–â–â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/mAP50-95(B)</td><td>â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–â–â–â–â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/precision(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/recall(B)</td><td>â–‚â–ƒâ–ƒâ–…â–…â–…â–…â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–â–â–â–‚</td></tr><tr><td>model/GFLOPs</td><td>â–</td></tr><tr><td>model/parameters</td><td>â–</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>â–</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.8665</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.73702</td></tr><tr><td>metrics/precision(B)</td><td>0.78814</td></tr><tr><td>metrics/recall(B)</td><td>0.43361</td></tr><tr><td>model/GFLOPs</td><td>6.443</td></tr><tr><td>model/parameters</td><td>2590425</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>68.655</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n_320</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/z3aqs5fz' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/z3aqs5fz</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 20 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_094622-z3aqs5fz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Running Validation...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 1.60.5 ms, read: 2.20.6 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.3Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.1it/s 0.2s\n",
      "                   all          3         19      0.788      0.433      0.866      0.737\n",
      "            light_blue          1          5      0.364          1      0.906      0.781\n",
      "             dark_blue          1          7          1          0      0.698       0.59\n",
      "                others          1          7          1      0.299      0.995       0.84\n",
      "Speed: 0.5ms preprocess, 52.1ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\runs\\detect\\val52\u001b[0m\n",
      "ğŸ“¦ Exporting to ONNX...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320\\weights\\best.pt' with input shape (1, 3, 320, 320) BCHW and output shape(s) (1, 7, 2100) (5.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.74...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.6s, saved as 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320\\weights\\best.onnx' (10.0 MB)\n",
      "\n",
      "Export complete (2.8s)\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320\\weights\\best.onnx imgsz=320  \n",
      "Validate:        yolo val task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320\\weights\\best.onnx imgsz=320 data=../datasets/bottle_cap/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "â±ï¸ Running Benchmark on: Bottle-Cap-Detection\\yolo11n_320\\weights\\best.onnx\n",
      "âœ… Speed Result: 41.11 ms (24.3 FPS)\n",
      "ğŸ”„ Re-connecting ke Run ID: z3aqs5fz...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_094932-z3aqs5fz</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/z3aqs5fz' target=\"_blank\">yolo11n_320</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/z3aqs5fz' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/z3aqs5fz</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data benchmark berhasil dikirim ke WandB!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>â–</td></tr><tr><td>inference/onnx_fps</td><td>â–</td></tr><tr><td>model/size_mb</td><td>â–</td></tr><tr><td>val/mAP50</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>41.10622</td></tr><tr><td>inference/onnx_fps</td><td>24.32722</td></tr><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.8665</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.73702</td></tr><tr><td>metrics/precision(B)</td><td>0.78814</td></tr><tr><td>metrics/recall(B)</td><td>0.43361</td></tr><tr><td>model/GFLOPs</td><td>6.443</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n_320</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/z3aqs5fz' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/z3aqs5fz</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_094932-z3aqs5fz\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”’ Sesi WandB ditutup.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "41.10621929168701"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jalankan Eksperimen 1: Ukuran 320, Augmentasi Aman\n",
    "run_experiment(\n",
    "    model_name='yolo11n.pt', \n",
    "    exp_name='yolo11n_320', \n",
    "    img_size=320, \n",
    "    use_safe_aug=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11213b62",
   "metadata": {},
   "source": [
    "### Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ca48960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ START EXPERIMENT: yolo11n_320_aug | Size: 320 | Safe Aug: True\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_094936-v4kvlv7d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/v4kvlv7d' target=\"_blank\">yolo11n_320_aug</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/v4kvlv7d' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/v4kvlv7d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›¡ï¸ Mengaktifkan SAFE MODE...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../datasets/bottle_cap/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=yolo11n_320_aug, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=Bottle-Cap-Detection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_aug, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.1, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431257  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,425 parameters, 2,590,409 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 1.90.4 ms, read: 2.50.3 MB/s, size: 52.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\train\\labels.cache... 9 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.7Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 1.70.5 ms, read: 2.30.5 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.0Kit/s 0.0s\n",
      "Plotting labels to G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_aug\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_aug\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50         0G      1.752      3.792     0.9203          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1s/it 2.2s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.3s\n",
      "                   all          3         19    0.00693      0.429     0.0134    0.00741\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50         0G      1.438      3.785     0.8998          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2s/it 2.3s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19    0.00819      0.476     0.0149    0.00917\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50         0G     0.9454      3.707     0.8468          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.1s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19     0.0071      0.476     0.0164    0.00893\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50         0G     0.9984      3.724     0.8563          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1s/it 2.2s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
      "                   all          3         19       0.01      0.619     0.0208     0.0102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50         0G      1.098      3.611     0.8244          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
      "                   all          3         19     0.0103      0.667     0.0238     0.0128\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50         0G      1.142      3.501     0.8394          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19     0.0137      0.714     0.0292     0.0193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50         0G      1.003      3.359     0.8151          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 2.0s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19     0.0133      0.714     0.0308     0.0206\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50         0G     0.8689      3.288     0.8264          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 2.0s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19     0.0163      0.762     0.0341     0.0252\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50         0G     0.8107      3.324     0.8203          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19     0.0164      0.762      0.035     0.0267\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50         0G      0.879      3.124      0.814         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.0s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
      "                   all          3         19       0.02       0.81     0.0436     0.0322\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50         0G     0.7545      3.014     0.7949          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 1.9s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19     0.0231      0.857     0.0468     0.0326\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50         0G     0.6962      2.728     0.7844          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.1it/s 0.3s\n",
      "                   all          3         19     0.0231      0.857     0.0468     0.0326\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50         0G     0.6785      2.869     0.7647          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.7it/s 0.3s\n",
      "                   all          3         19      0.026      0.905     0.0498     0.0348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50         0G     0.5922      2.545     0.8099          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
      "                   all          3         19     0.0283      0.952     0.0521     0.0377\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50         0G     0.7158      2.372     0.7848          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.6s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
      "                   all          3         19     0.0283      0.952     0.0521     0.0377\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50         0G     0.7507       1.97     0.7899          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 2.0s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
      "                   all          3         19     0.0306          1     0.0559     0.0403\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50         0G     0.6501      2.116     0.7737          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19     0.0304          1     0.0586     0.0428\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50         0G     0.7122      2.449     0.8059          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19     0.0304          1     0.0586     0.0428\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50         0G     0.6216      2.095     0.7947         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19     0.0288          1     0.0573      0.043\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50         0G     0.5865      2.286      0.786          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19     0.0288          1     0.0573      0.043\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50         0G      0.858      1.659     0.7754          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 1.9s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
      "                   all          3         19     0.0277          1      0.228      0.168\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50         0G     0.6973      2.011     0.7948          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.3s\n",
      "                   all          3         19     0.0277          1      0.228      0.168\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50         0G     0.6426      2.007     0.7991          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 2.0s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19     0.0272          1      0.228      0.161\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50         0G     0.6651      2.173     0.7641          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.7s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.4s\n",
      "                   all          3         19     0.0272          1      0.228      0.161\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50         0G     0.6532       1.45     0.8086          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19     0.0257          1      0.296       0.21\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50         0G     0.5847      1.337     0.7549          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
      "                   all          3         19     0.0257          1      0.296       0.21\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50         0G     0.5863      1.477     0.7887          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.6s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
      "                   all          3         19     0.0257          1      0.296       0.21\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50         0G     0.7241       1.91     0.7845          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
      "                   all          3         19      0.025          1      0.336      0.243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50         0G     0.7932      1.927      0.806          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.6s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
      "                   all          3         19      0.025          1      0.336      0.243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50         0G     0.7793      1.882     0.8137          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 1.9s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
      "                   all          3         19     0.0247          1       0.42      0.314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50         0G     0.6339      1.178     0.7484          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19     0.0247          1       0.42      0.314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50         0G     0.7833       1.31     0.8256          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.1it/s 0.3s\n",
      "                   all          3         19     0.0247          1       0.42      0.314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50         0G      0.558      1.128     0.7964         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.0s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "                   all          3         19      0.984      0.267      0.708      0.572\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50         0G     0.5674      1.755     0.7774          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19      0.984      0.267      0.708      0.572\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50         0G     0.5453      1.275     0.8053          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.0it/s 0.5s\n",
      "                   all          3         19      0.984      0.267      0.708      0.572\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50         0G     0.6195      1.785     0.7666          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19          1      0.329      0.916      0.785\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50         0G     0.5335     0.9902     0.8058          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.3s\n",
      "                   all          3         19          1      0.329      0.916      0.785\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50         0G       0.63      1.742     0.7736          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19          1      0.329      0.916      0.785\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50         0G     0.5901      1.173      0.787          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.0s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.5it/s 0.3s\n",
      "                   all          3         19       0.95      0.333      0.978       0.84\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50         0G     0.5085      1.037     0.8121         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19       0.95      0.333      0.978       0.84\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50         0G     0.6845      1.143     0.7872          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19       0.95      0.333      0.978       0.84\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50         0G     0.6279       1.15     0.7558          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1s/it 2.1s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.1it/s 0.3s\n",
      "                   all          3         19      0.932      0.403      0.989      0.858\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50         0G     0.5174      1.029     0.7828          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
      "                   all          3         19      0.932      0.403      0.989      0.858\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50         0G     0.5729      1.675     0.7543          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19      0.932      0.403      0.989      0.858\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50         0G      0.605      1.021     0.7804          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.5s\n",
      "                   all          3         19      0.932      0.403      0.989      0.858\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50         0G     0.5365     0.9407     0.8052          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 2.0s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.1it/s 0.3s\n",
      "                   all          3         19      0.928      0.644      0.995      0.877\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50         0G      0.519     0.8783     0.7787          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19      0.928      0.644      0.995      0.877\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50         0G     0.5873      1.696     0.7724          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
      "                   all          3         19      0.928      0.644      0.995      0.877\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50         0G      0.583      1.553     0.7672          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19      0.928      0.644      0.995      0.877\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50         0G     0.5772     0.9516     0.7784          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1s/it 2.2s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19      0.917      0.934      0.995      0.886\n",
      "\n",
      "50 epochs completed in 0.040 hours.\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_aug\\weights\\last.pt, 5.4MB\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_aug\\weights\\best.pt, 5.4MB\n",
      "\n",
      "Validating G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_aug\\weights\\best.pt...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.2it/s 0.5s\n",
      "                   all          3         19      0.917      0.932      0.995      0.886\n",
      "            light_blue          1          5       0.77          1      0.995      0.955\n",
      "             dark_blue          1          7      0.981          1      0.995      0.858\n",
      "                others          1          7          1      0.797      0.995      0.846\n",
      "Speed: 0.5ms preprocess, 62.4ms inference, 0.0ms loss, 4.0ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_aug\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg1</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg2</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>metrics/mAP50(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/mAP50-95(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/precision(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡</td></tr><tr><td>metrics/recall(B)</td><td>â–ƒâ–ƒâ–ƒâ–„â–…â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–…â–…â–…â–‡</td></tr><tr><td>model/GFLOPs</td><td>â–</td></tr><tr><td>model/parameters</td><td>â–</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>â–</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.995</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.88647</td></tr><tr><td>metrics/precision(B)</td><td>0.91703</td></tr><tr><td>metrics/recall(B)</td><td>0.9337</td></tr><tr><td>model/GFLOPs</td><td>6.443</td></tr><tr><td>model/parameters</td><td>2590425</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>59.289</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n_320_aug</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/v4kvlv7d' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/v4kvlv7d</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 20 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_094936-v4kvlv7d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Running Validation...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 1.90.8 ms, read: 2.20.5 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.4Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.2it/s 0.2s\n",
      "                   all          3         19      0.917      0.932      0.995      0.886\n",
      "            light_blue          1          5       0.77          1      0.995      0.955\n",
      "             dark_blue          1          7      0.981          1      0.995      0.858\n",
      "                others          1          7          1      0.797      0.995      0.846\n",
      "Speed: 0.3ms preprocess, 53.4ms inference, 0.0ms loss, 4.1ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\runs\\detect\\val53\u001b[0m\n",
      "ğŸ“¦ Exporting to ONNX...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_aug\\weights\\best.pt' with input shape (1, 3, 320, 320) BCHW and output shape(s) (1, 7, 2100) (5.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.74...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.3s, saved as 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_aug\\weights\\best.onnx' (10.0 MB)\n",
      "\n",
      "Export complete (2.5s)\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_aug\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_aug\\weights\\best.onnx imgsz=320  \n",
      "Validate:        yolo val task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_aug\\weights\\best.onnx imgsz=320 data=../datasets/bottle_cap/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "â±ï¸ Running Benchmark on: Bottle-Cap-Detection\\yolo11n_320_aug\\weights\\best.onnx\n",
      "âœ… Speed Result: 38.23 ms (26.2 FPS)\n",
      "ğŸ”„ Re-connecting ke Run ID: v4kvlv7d...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_095243-v4kvlv7d</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/v4kvlv7d' target=\"_blank\">yolo11n_320_aug</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/v4kvlv7d' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/v4kvlv7d</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data benchmark berhasil dikirim ke WandB!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>â–</td></tr><tr><td>inference/onnx_fps</td><td>â–</td></tr><tr><td>model/size_mb</td><td>â–</td></tr><tr><td>val/mAP50</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>38.22703</td></tr><tr><td>inference/onnx_fps</td><td>26.1595</td></tr><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.995</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.88647</td></tr><tr><td>metrics/precision(B)</td><td>0.91703</td></tr><tr><td>metrics/recall(B)</td><td>0.9337</td></tr><tr><td>model/GFLOPs</td><td>6.443</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n_320_aug</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/v4kvlv7d' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/v4kvlv7d</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_095243-v4kvlv7d\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”’ Sesi WandB ditutup.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38.22702884674072"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jalankan Eksperimen 1: Ukuran 320, Augmentasi Aman\n",
    "run_experiment(\n",
    "    model_name='yolo11n.pt', \n",
    "    exp_name='yolo11n_320_aug', \n",
    "    img_size=320, \n",
    "    use_safe_aug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8665e74f",
   "metadata": {},
   "source": [
    "### FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c9d29d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ START FP16 EXPERIMENT: yolo11n_320_fp16 | Size: 320 | Safe Aug: True\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_095247-5xdfcebf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/5xdfcebf' target=\"_blank\">yolo11n_320_fp16</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/5xdfcebf' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/5xdfcebf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›¡ï¸ Mengaktifkan SAFE MODE (Augmentasi Warna OFF)...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../datasets/bottle_cap/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, imgsz=320, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=yolo11n_320_fp16, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=Bottle-Cap-Detection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_fp16, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.1, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431257  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,425 parameters, 2,590,409 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 2.31.1 ms, read: 2.50.6 MB/s, size: 52.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\train\\labels.cache... 9 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.4Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 1.70.8 ms, read: 2.30.6 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.5Kit/s 0.0s\n",
      "Plotting labels to G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_fp16\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 320 train, 320 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_fp16\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50         0G      1.752      3.792     0.9203          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1s/it 2.2s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19    0.00693      0.429     0.0134    0.00741\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50         0G      1.438      3.785     0.8998          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2s/it 2.4s2.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.3s\n",
      "                   all          3         19    0.00819      0.476     0.0149    0.00917\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50         0G     0.9454      3.707     0.8468          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.1s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19     0.0071      0.476     0.0164    0.00893\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50         0G     0.9984      3.724     0.8563          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1s/it 2.2s2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19       0.01      0.619     0.0208     0.0102\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50         0G      1.098      3.611     0.8244          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.0s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.1it/s 0.3s\n",
      "                   all          3         19     0.0103      0.667     0.0238     0.0128\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50         0G      1.142      3.501     0.8394          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 1.9s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
      "                   all          3         19     0.0137      0.714     0.0292     0.0193\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50         0G      1.003      3.359     0.8151          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.6s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.3s\n",
      "                   all          3         19     0.0133      0.714     0.0308     0.0206\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50         0G     0.8689      3.288     0.8264          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.0s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
      "                   all          3         19     0.0163      0.762     0.0341     0.0252\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50         0G     0.8107      3.324     0.8203          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
      "                   all          3         19     0.0164      0.762      0.035     0.0267\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50         0G      0.879      3.124      0.814         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.1s2.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19       0.02       0.81     0.0436     0.0322\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50         0G     0.7545      3.014     0.7949          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19     0.0231      0.857     0.0468     0.0326\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50         0G     0.6962      2.728     0.7844          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.1it/s 0.3s\n",
      "                   all          3         19     0.0231      0.857     0.0468     0.0326\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50         0G     0.6785      2.869     0.7647          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
      "                   all          3         19      0.026      0.905     0.0498     0.0348\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50         0G     0.5922      2.545     0.8099          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 1.9s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19     0.0283      0.952     0.0521     0.0377\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50         0G     0.7158      2.372     0.7848          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.3s\n",
      "                   all          3         19     0.0283      0.952     0.0521     0.0377\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50         0G     0.7507       1.97     0.7899          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19     0.0306          1     0.0559     0.0403\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50         0G     0.6501      2.116     0.7737          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.3s\n",
      "                   all          3         19     0.0304          1     0.0586     0.0428\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50         0G     0.7122      2.449     0.8059          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.1it/s 0.5s\n",
      "                   all          3         19     0.0304          1     0.0586     0.0428\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50         0G     0.6216      2.095     0.7947         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19     0.0288          1     0.0573      0.043\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50         0G     0.5865      2.286      0.786          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
      "                   all          3         19     0.0288          1     0.0573      0.043\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50         0G      0.858      1.659     0.7754          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 2.0s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "                   all          3         19     0.0277          1      0.228      0.168\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50         0G     0.6973      2.011     0.7948          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
      "                   all          3         19     0.0277          1      0.228      0.168\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50         0G     0.6426      2.007     0.7991          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1s/it 2.2s3.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
      "                   all          3         19     0.0272          1      0.228      0.161\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50         0G     0.6651      2.173     0.7641          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "                   all          3         19     0.0272          1      0.228      0.161\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50         0G     0.6532       1.45     0.8086          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.0s2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
      "                   all          3         19     0.0257          1      0.296       0.21\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50         0G     0.5847      1.337     0.7549          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19     0.0257          1      0.296       0.21\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50         0G     0.5863      1.477     0.7887          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.3s\n",
      "                   all          3         19     0.0257          1      0.296       0.21\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50         0G     0.7241       1.91     0.7845          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 1.9s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6it/s 0.3s\n",
      "                   all          3         19      0.025          1      0.336      0.243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50         0G     0.7932      1.927      0.806          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19      0.025          1      0.336      0.243\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50         0G     0.7793      1.882     0.8137          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
      "                   all          3         19     0.0247          1       0.42      0.314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50         0G     0.6339      1.178     0.7484          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
      "                   all          3         19     0.0247          1       0.42      0.314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50         0G     0.7833       1.31     0.8256          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19     0.0247          1       0.42      0.314\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50         0G      0.558      1.128     0.7964         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.1s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19      0.984      0.267      0.708      0.572\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50         0G     0.5674      1.755     0.7774          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19      0.984      0.267      0.708      0.572\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50         0G     0.5453      1.275     0.8053          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19      0.984      0.267      0.708      0.572\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50         0G     0.6195      1.785     0.7666          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 1.9s1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19          1      0.329      0.916      0.785\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50         0G     0.5335     0.9902     0.8058          9        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19          1      0.329      0.916      0.785\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50         0G       0.63      1.742     0.7736          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 1.9s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19          1      0.329      0.916      0.785\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50         0G     0.5901      1.173      0.787          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.3s\n",
      "                   all          3         19       0.95      0.333      0.978       0.84\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50         0G     0.5085      1.037     0.8121         10        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 1.9s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.4s\n",
      "                   all          3         19       0.95      0.333      0.978       0.84\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50         0G     0.6845      1.143     0.7872          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 1.9s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19       0.95      0.333      0.978       0.84\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50         0G     0.6279       1.15     0.7558          3        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0it/s 2.0s2.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "                   all          3         19      0.932      0.403      0.989      0.858\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50         0G     0.5174      1.029     0.7828          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
      "                   all          3         19      0.932      0.403      0.989      0.858\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50         0G     0.5729      1.675     0.7543          6        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.0s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19      0.932      0.403      0.989      0.858\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50         0G      0.605      1.021     0.7804          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19      0.932      0.403      0.989      0.858\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50         0G     0.5365     0.9407     0.8052          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.0s/it 2.1s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
      "                   all          3         19      0.928      0.644      0.995      0.877\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50         0G      0.519     0.8783     0.7787          8        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19      0.928      0.644      0.995      0.877\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50         0G     0.5873      1.696     0.7724          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.7s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "                   all          3         19      0.928      0.644      0.995      0.877\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50         0G      0.583      1.553     0.7672          5        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.5it/s 0.4s\n",
      "                   all          3         19      0.928      0.644      0.995      0.877\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50         0G     0.5772     0.9516     0.7784          7        320: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.9s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.7it/s 0.4s\n",
      "                   all          3         19      0.917      0.934      0.995      0.886\n",
      "\n",
      "50 epochs completed in 0.041 hours.\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_fp16\\weights\\last.pt, 5.4MB\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_fp16\\weights\\best.pt, 5.4MB\n",
      "\n",
      "Validating G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_fp16\\weights\\best.pt...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.4it/s 0.4s\n",
      "                   all          3         19      0.917      0.932      0.995      0.886\n",
      "            light_blue          1          5       0.77          1      0.995      0.955\n",
      "             dark_blue          1          7      0.981          1      0.995      0.858\n",
      "                others          1          7          1      0.797      0.995      0.846\n",
      "Speed: 0.4ms preprocess, 51.5ms inference, 0.0ms loss, 3.9ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_fp16\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>â–â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–‡â–†â–†â–…â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg1</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg2</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–ƒâ–‚</td></tr><tr><td>metrics/mAP50(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/mAP50-95(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–…â–…â–…â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/precision(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡</td></tr><tr><td>metrics/recall(B)</td><td>â–ƒâ–ƒâ–ƒâ–„â–…â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–â–â–â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–‚â–…â–…â–…â–‡</td></tr><tr><td>model/GFLOPs</td><td>â–</td></tr><tr><td>model/parameters</td><td>â–</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>â–</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.995</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.88647</td></tr><tr><td>metrics/precision(B)</td><td>0.91703</td></tr><tr><td>metrics/recall(B)</td><td>0.9337</td></tr><tr><td>model/GFLOPs</td><td>6.443</td></tr><tr><td>model/parameters</td><td>2590425</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>81.125</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n_320_fp16</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/5xdfcebf' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/5xdfcebf</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 20 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_095247-5xdfcebf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Running Validation...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 1.90.8 ms, read: 1.90.3 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 1.5Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.6it/s 0.2s\n",
      "                   all          3         19      0.917      0.932      0.995      0.886\n",
      "            light_blue          1          5       0.77          1      0.995      0.955\n",
      "             dark_blue          1          7      0.981          1      0.995      0.858\n",
      "                others          1          7          1      0.797      0.995      0.846\n",
      "Speed: 0.3ms preprocess, 49.3ms inference, 0.0ms loss, 3.8ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\runs\\detect\\val54\u001b[0m\n",
      "\n",
      "ğŸ“¦ Exporting to OpenVINO FP16...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_fp16\\weights\\best.pt' with input shape (1, 3, 320, 320) BCHW and output shape(s) (1, 7, 2100) (5.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m starting export with openvino 2024.6.0-17404-4c0f47d2335-releases/2024/6...\n",
      "\u001b[34m\u001b[1mOpenVINO:\u001b[0m export success  11.5s, saved as 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_fp16\\weights\\best_openvino_model\\' (5.3 MB)\n",
      "\n",
      "Export complete (11.8s)\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_fp16\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_fp16\\weights\\best_openvino_model imgsz=320 half \n",
      "Validate:        yolo val task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_320_fp16\\weights\\best_openvino_model imgsz=320 data=../datasets/bottle_cap/data.yaml half \n",
      "Visualize:       https://netron.app\n",
      "â±ï¸ Running Benchmark on: Bottle-Cap-Detection\\yolo11n_320_fp16\\weights\\best_openvino_model\n",
      "Loading Bottle-Cap-Detection\\yolo11n_320_fp16\\weights\\best_openvino_model for OpenVINO inference...\n",
      "Using OpenVINO LATENCY mode for batch=1 inference on (CPU)...\n",
      "âœ… Speed Result (FP16): 38.81 ms (25.8 FPS)\n",
      "ğŸ”„ Re-connecting ke Run ID: 5xdfcebf...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_095606-5xdfcebf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/5xdfcebf' target=\"_blank\">yolo11n_320_fp16</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/5xdfcebf' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/5xdfcebf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data FP16 berhasil dikirim ke WandB!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>â–</td></tr><tr><td>inference/openvino_fp16_fps</td><td>â–</td></tr><tr><td>model/size_mb</td><td>â–</td></tr><tr><td>val/mAP50</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>38.81073</td></tr><tr><td>inference/openvino_fp16_fps</td><td>25.76607</td></tr><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.995</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.88647</td></tr><tr><td>metrics/precision(B)</td><td>0.91703</td></tr><tr><td>metrics/recall(B)</td><td>0.9337</td></tr><tr><td>model/GFLOPs</td><td>6.443</td></tr><tr><td>+17</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n_320_fp16</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/5xdfcebf' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/5xdfcebf</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_095606-5xdfcebf\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”’ WandB Session Closed.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "38.81073474884033"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Jalankan FP16 dengan Size 320\n",
    "run_experiment_fp16(\n",
    "    model_name='yolo11n.pt',       # atau 'yolo11n.pt'\n",
    "    exp_name='yolo11n_320_fp16', \n",
    "    img_size=320, \n",
    "    use_safe_aug=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464945ab",
   "metadata": {},
   "source": [
    "### Yolo11n 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff85800a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ START EXPERIMENT: yolo11n_256 | Size: 256 | Safe Aug: True\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_095610-hmlmbaqc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/hmlmbaqc' target=\"_blank\">yolo11n_256</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/hmlmbaqc' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/hmlmbaqc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ›¡ï¸ Mengaktifkan SAFE MODE...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../datasets/bottle_cap/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=50, erasing=0.4, exist_ok=True, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.0, hsv_s=0.0, hsv_v=0.0, imgsz=256, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolo11n.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=yolo11n_256, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=15, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=Bottle-Cap-Detection, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_256, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.1, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n",
      "Overriding model.yaml nc=80 with nc=3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      6640  ultralytics.nn.modules.block.C3k2            [32, 64, 1, False, 0.25]      \n",
      "  3                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      "  4                  -1  1     26080  ultralytics.nn.modules.block.C3k2            [64, 128, 1, False, 0.25]     \n",
      "  5                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      "  6                  -1  1     87040  ultralytics.nn.modules.block.C3k2            [128, 128, 1, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    346112  ultralytics.nn.modules.block.C3k2            [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.C2PSA           [256, 256, 1]                 \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    111296  ultralytics.nn.modules.block.C3k2            [384, 128, 1, False]          \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     32096  ultralytics.nn.modules.block.C3k2            [256, 64, 1, False]           \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1     86720  ultralytics.nn.modules.block.C3k2            [192, 128, 1, False]          \n",
      " 20                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    378880  ultralytics.nn.modules.block.C3k2            [384, 256, 1, True]           \n",
      " 23        [16, 19, 22]  1    431257  ultralytics.nn.modules.head.Detect           [3, [64, 128, 256]]           \n",
      "YOLO11n summary: 181 layers, 2,590,425 parameters, 2,590,409 gradients, 6.4 GFLOPs\n",
      "\n",
      "Transferred 448/499 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 1.80.5 ms, read: 2.50.2 MB/s, size: 52.2 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\train\\labels.cache... 9 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 9/9 4.5Kit/s 0.0s\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 1.70.5 ms, read: 1.90.6 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 3.0Kit/s 0.0s\n",
      "Plotting labels to G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_256\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001429, momentum=0.9) with parameter groups 81 weight(decay=0.0), 88 weight(decay=0.0005), 87 bias(decay=0.0)\n",
      "Image sizes 256 train, 256 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_256\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       1/50         0G      2.203      3.966      1.009          5        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3s/it 2.5s2.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19    0.00644      0.381     0.0064    0.00421\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       2/50         0G      1.727      3.903     0.9406          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1s/it 2.1s2.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.1it/s 0.3s\n",
      "                   all          3         19    0.00642      0.381    0.00636    0.00445\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       3/50         0G      1.321       3.78     0.8447          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.1it/s 0.2s\n",
      "                   all          3         19    0.00757      0.429    0.00773    0.00407\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       4/50         0G      1.137      3.767     0.7992          5        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.1it/s 1.8s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.3s\n",
      "                   all          3         19     0.0137      0.667     0.0176    0.00827\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       5/50         0G      1.376      3.742     0.8423          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.0it/s 0.3s\n",
      "                   all          3         19     0.0142      0.667     0.0249     0.0123\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       6/50         0G      1.407      3.684     0.8335          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.2it/s 0.2s\n",
      "                   all          3         19     0.0143      0.667     0.0349     0.0171\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       7/50         0G      1.395      3.595     0.8438          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.7it/s 0.3s\n",
      "                   all          3         19     0.0145      0.667     0.0372      0.023\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       8/50         0G      1.235      3.503     0.8163          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.5s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19     0.0154      0.714      0.044     0.0308\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K       9/50         0G     0.8465      3.474     0.8145          5        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s2.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.0it/s 0.3s\n",
      "                   all          3         19     0.0155      0.714     0.0473     0.0324\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      10/50         0G     0.9063      3.343     0.7685         10        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.9it/s 0.3s\n",
      "                   all          3         19     0.0202      0.762     0.0511     0.0363\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      11/50         0G     0.9578      3.257     0.7917          6        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.2it/s 0.2s\n",
      "                   all          3         19     0.0199      0.762     0.0465      0.034\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      12/50         0G     0.9194      3.051     0.7864          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.3s1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19     0.0199      0.762     0.0465      0.034\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      13/50         0G      0.908      3.189     0.7831          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s1.7s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19     0.0322      0.905     0.0588     0.0385\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      14/50         0G     0.8021      2.991     0.8033          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19     0.0385          1     0.0683     0.0428\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      15/50         0G     0.7644      2.799     0.8253          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.3s1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.1it/s 0.2s\n",
      "                   all          3         19     0.0385          1     0.0683     0.0428\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      16/50         0G      0.766      2.528     0.7849          3        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.6s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6it/s 0.3s\n",
      "                   all          3         19     0.0336      0.952     0.0624     0.0448\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      17/50         0G     0.6874      2.598     0.7817          6        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.3s\n",
      "                   all          3         19     0.0325      0.952     0.0635     0.0458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      18/50         0G     0.8781      2.831     0.7507          5        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.3s1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.5it/s 0.3s\n",
      "                   all          3         19     0.0325      0.952     0.0635     0.0458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      19/50         0G     0.7169      2.577     0.7526         10        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.0it/s 0.2s\n",
      "                   all          3         19     0.0318          1     0.0606     0.0405\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      20/50         0G     0.7582       2.67     0.7589          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.2it/s 0.3s\n",
      "                   all          3         19     0.0318          1     0.0606     0.0405\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      21/50         0G     0.8928      1.983     0.7958          3        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.9it/s 0.3s\n",
      "                   all          3         19     0.0313          1     0.0614      0.041\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      22/50         0G     0.8333      2.547      0.765          6        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.1s1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.7it/s 0.3s\n",
      "                   all          3         19     0.0313          1     0.0614      0.041\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      23/50         0G     0.7378      2.536     0.7734          6        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s2.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.6it/s 0.4s\n",
      "                   all          3         19     0.0297          1       0.06     0.0422\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      24/50         0G     0.7669      2.508     0.7361          5        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19     0.0297          1       0.06     0.0422\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      25/50         0G     0.7998      1.959     0.8117          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s2.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19     0.0292          1      0.164      0.117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      26/50         0G     0.6539      1.858     0.7602          9        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.2s1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.7it/s 0.3s\n",
      "                   all          3         19     0.0292          1      0.164      0.117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      27/50         0G     0.7102      1.711      0.799          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.3s1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.9it/s 0.3s\n",
      "                   all          3         19     0.0292          1      0.164      0.117\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      28/50         0G      1.005      2.411     0.8528          5        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s1.8s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.9it/s 0.3s\n",
      "                   all          3         19     0.0267          1      0.252       0.17\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      29/50         0G     0.8956      2.044     0.8088          6        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.2s1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19     0.0267          1      0.252       0.17\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      30/50         0G     0.8998      2.042     0.7359          6        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s2.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.9it/s 0.3s\n",
      "                   all          3         19     0.0252          1      0.365      0.257\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      31/50         0G     0.6549      1.452     0.7717          8        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.2s1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6it/s 0.3s\n",
      "                   all          3         19     0.0252          1      0.365      0.257\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      32/50         0G     0.9516       1.25     0.8663          3        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.2s1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.0it/s 0.2s\n",
      "                   all          3         19     0.0252          1      0.365      0.257\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      33/50         0G      0.663      1.381     0.7602         10        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.2it/s 0.2s\n",
      "                   all          3         19     0.0246          1      0.509        0.4\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      34/50         0G     0.6858      1.853     0.7853          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.2s1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.5it/s 0.2s\n",
      "                   all          3         19     0.0246          1      0.509        0.4\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      35/50         0G     0.6302      1.395     0.7979          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.7it/s 1.2s1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19     0.0246          1      0.509        0.4\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      36/50         0G     0.8488      2.072     0.7626          5        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.5s1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.8it/s 0.4s\n",
      "                   all          3         19      0.832      0.384        0.6      0.505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      37/50         0G     0.6578      1.173       0.79          9        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.3s1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.7it/s 0.3s\n",
      "                   all          3         19      0.832      0.384        0.6      0.505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      38/50         0G     0.7663      2.022     0.8262          5        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.3s1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.0it/s 0.2s\n",
      "                   all          3         19      0.832      0.384        0.6      0.505\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      39/50         0G     0.6768       1.28     0.7599          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.6s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19          1      0.278      0.732      0.633\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      40/50         0G      0.594      1.183     0.8122         10        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.3s1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8it/s 0.3s\n",
      "                   all          3         19          1      0.278      0.732      0.633\n",
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      41/50         0G     0.8466        1.1     0.7694          3        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.4it/s 1.4s1.6s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19          1      0.278      0.732      0.633\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      42/50         0G     0.6935      1.098     0.7501          3        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.6s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19      0.973      0.333      0.901      0.754\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      43/50         0G     0.5871      1.057     0.7825          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.6it/s 1.3s1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6it/s 0.3s\n",
      "                   all          3         19      0.973      0.333      0.901      0.754\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      44/50         0G     0.7387      1.813     0.8195          6        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.4s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.2it/s 0.2s\n",
      "                   all          3         19      0.973      0.333      0.901      0.754\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      45/50         0G     0.6598      1.059     0.7638          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.3s1.5s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.1it/s 0.2s\n",
      "                   all          3         19      0.973      0.333      0.901      0.754\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      46/50         0G     0.5808     0.9747     0.8504          8        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.2it/s 1.7s1.1s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.3it/s 0.3s\n",
      "                   all          3         19      0.956      0.488      0.995      0.817\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      47/50         0G     0.6768      1.044     0.7635          8        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.9s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.8it/s 0.3s\n",
      "                   all          3         19      0.956      0.488      0.995      0.817\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      48/50         0G     0.7892        1.9     0.7745          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.4s1.3s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.6it/s 0.3s\n",
      "                   all          3         19      0.956      0.488      0.995      0.817\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      49/50         0G     0.6425      1.968      0.814          5        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.5it/s 1.4s1.4s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.7it/s 0.3s\n",
      "                   all          3         19      0.956      0.488      0.995      0.817\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
      "\u001b[K      50/50         0G      0.601          1     0.7889          7        256: 100% â”â”â”â”â”â”â”â”â”â”â”â” 2/2 1.3it/s 1.5s1.2s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 3.4it/s 0.3s\n",
      "                   all          3         19      0.948      0.637      0.989      0.815\n",
      "\n",
      "50 epochs completed in 0.034 hours.\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_256\\weights\\last.pt, 5.4MB\n",
      "Optimizer stripped from G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_256\\weights\\best.pt, 5.4MB\n",
      "\n",
      "Validating G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_256\\weights\\best.pt...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 2.3it/s 0.4s\n",
      "                   all          3         19      0.956      0.488      0.995      0.817\n",
      "            light_blue          1          5      0.867          1      0.995      0.792\n",
      "             dark_blue          1          7          1      0.271      0.995      0.827\n",
      "                others          1          7          1      0.193      0.995      0.832\n",
      "Speed: 0.3ms preprocess, 55.3ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_256\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg1</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–‡â–†â–†â–†â–…â–„â–„â–ƒâ–ƒâ–‚</td></tr><tr><td>lr/pg2</td><td>â–â–‚â–‚â–ƒâ–ƒâ–„â–„â–…â–…â–…â–†â–†â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‡â–‡â–‡â–†â–†â–†â–…â–…â–„â–„â–„â–ƒâ–‚</td></tr><tr><td>metrics/mAP50(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–ƒâ–„â–„â–…â–…â–…â–…â–…â–†â–†â–†â–‡â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/mAP50-95(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–„â–„â–„â–…â–…â–†â–†â–†â–‡â–‡â–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/precision(B)</td><td>â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–‡â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ</td></tr><tr><td>metrics/recall(B)</td><td>â–‚â–‚â–‚â–…â–…â–…â–…â–…â–†â–†â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–‚â–‚â–â–â–â–‚â–‚â–‚â–ƒâ–ƒâ–ƒ</td></tr><tr><td>model/GFLOPs</td><td>â–</td></tr><tr><td>model/parameters</td><td>â–</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>â–</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.98917</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.81524</td></tr><tr><td>metrics/precision(B)</td><td>0.94759</td></tr><tr><td>metrics/recall(B)</td><td>0.63694</td></tr><tr><td>model/GFLOPs</td><td>6.443</td></tr><tr><td>model/parameters</td><td>2590425</td></tr><tr><td>model/speed_PyTorch(ms)</td><td>76.628</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n_256</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/hmlmbaqc' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/hmlmbaqc</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 20 media file(s), 10 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_095610-hmlmbaqc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š Running Validation...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "YOLO11n summary (fused): 100 layers, 2,582,737 parameters, 0 gradients, 6.3 GFLOPs\n",
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 1.60.4 ms, read: 2.30.6 MB/s, size: 43.4 KB)\n",
      "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\datasets\\bottle_cap\\valid\\labels.cache... 3 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 3/3 2.0Kit/s 0.0s\n",
      "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 1/1 4.5it/s 0.2s\n",
      "                   all          3         19      0.956      0.488      0.995      0.817\n",
      "            light_blue          1          5      0.867          1      0.995      0.792\n",
      "             dark_blue          1          7          1      0.271      0.995      0.827\n",
      "                others          1          7          1      0.193      0.995      0.832\n",
      "Speed: 0.3ms preprocess, 51.6ms inference, 0.0ms loss, 2.2ms postprocess per image\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\runs\\detect\\val55\u001b[0m\n",
      "ğŸ“¦ Exporting to ONNX...\n",
      "Ultralytics 8.3.231  Python-3.11.9 torch-2.4.1+cpu CPU (12th Gen Intel Core i5-1235U)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_256\\weights\\best.pt' with input shape (1, 3, 256, 256) BCHW and output shape(s) (1, 7, 1344) (5.2 MB)\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.19.1 opset 12...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m slimming with onnxslim 0.1.74...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  2.3s, saved as 'G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_256\\weights\\best.onnx' (10.0 MB)\n",
      "\n",
      "Export complete (2.5s)\n",
      "Results saved to \u001b[1mG:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_256\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_256\\weights\\best.onnx imgsz=256  \n",
      "Validate:        yolo val task=detect model=G:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\Bottle-Cap-Detection\\yolo11n_256\\weights\\best.onnx imgsz=256 data=../datasets/bottle_cap/data.yaml  \n",
      "Visualize:       https://netron.app\n",
      "â±ï¸ Running Benchmark on: Bottle-Cap-Detection\\yolo11n_256\\weights\\best.onnx\n",
      "âœ… Speed Result: 27.11 ms (36.9 FPS)\n",
      "ğŸ”„ Re-connecting ke Run ID: hmlmbaqc...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.23.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>g:\\My Drive\\We Work The Talk\\Ada Mata - Machine Learning Engineer\\ada_mata_mle\\notebooks\\wandb\\run-20251125_095852-hmlmbaqc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Resuming run <strong><a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/hmlmbaqc' target=\"_blank\">yolo11n_256</a></strong> to <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/hmlmbaqc' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/hmlmbaqc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Data benchmark berhasil dikirim ke WandB!\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>â–</td></tr><tr><td>inference/onnx_fps</td><td>â–</td></tr><tr><td>model/size_mb</td><td>â–</td></tr><tr><td>val/mAP50</td><td>â–</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>inference/latency_ms</td><td>27.11026</td></tr><tr><td>inference/onnx_fps</td><td>36.88641</td></tr><tr><td>lr/pg0</td><td>4e-05</td></tr><tr><td>lr/pg1</td><td>4e-05</td></tr><tr><td>lr/pg2</td><td>4e-05</td></tr><tr><td>metrics/mAP50(B)</td><td>0.98917</td></tr><tr><td>metrics/mAP50-95(B)</td><td>0.81524</td></tr><tr><td>metrics/precision(B)</td><td>0.94759</td></tr><tr><td>metrics/recall(B)</td><td>0.63694</td></tr><tr><td>model/GFLOPs</td><td>6.443</td></tr><tr><td>+16</td><td>...</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">yolo11n_256</strong> at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/hmlmbaqc' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection/runs/hmlmbaqc</a><br> View project at: <a href='https://wandb.ai/wikan-project/Bottle-Cap-Detection' target=\"_blank\">https://wandb.ai/wikan-project/Bottle-Cap-Detection</a><br>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20251125_095852-hmlmbaqc\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”’ Sesi WandB ditutup.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "27.110257148742676"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Coba Size 256 (Sweet Spot?)\n",
    "run_experiment(\n",
    "    model_name='yolo11n.pt',  # Pastikan ini menunjuk ke checkpoint terbaikmu\n",
    "    exp_name='yolo11n_256',\n",
    "    img_size=256,             # <--- Turunkan resolusi\n",
    "    use_safe_aug=True\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ada-mata-mle-3IEznrPG-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
